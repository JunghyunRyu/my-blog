import asyncio
import json
import os
import re
from datetime import datetime
from typing import List, Dict, Any, Optional
import aiofiles
from playwright.async_api import async_playwright, Page, Response
from .config import Config
from .auth_manager import AuthManager

class CokacScraper:
    """ì½”ë“œê¹ëŠ”ë…¸ì¸ ì‚¬ì´íŠ¸ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ìŠ¤í¬ë˜í¼"""
    
    def __init__(self):
        self.config = Config()
        self.auth_manager = AuthManager()
        self.transcript_data = []
        self.api_responses = []
        
    async def scrape_lecture(self, lecture_url: str) -> List[Dict[str, Any]]:
        """
        ê°•ì˜ í˜ì´ì§€ì˜ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ìŠ¤í¬ë˜í•‘
        
        Args:
            lecture_url: ìŠ¤í¬ë˜í•‘í•  ê°•ì˜ URL
            
        Returns:
            ì¶”ì¶œëœ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        print(f"ğŸ¯ ê°•ì˜ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {lecture_url}")
        
        # URL ìœ íš¨ì„± ê²€ì‚¬
        if not self._is_valid_cokac_url(lecture_url):
            print(f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì½”ë“œê¹ëŠ”ë…¸ì¸ URLì…ë‹ˆë‹¤: {lecture_url}")
            return []
        
        async with async_playwright() as p:
            try:
                browser, context = await self.auth_manager.create_authenticated_context(p)
                page = await context.new_page()
                
                # ë„¤íŠ¸ì›Œí¬ ì‘ë‹µ í›„í‚¹ ì„¤ì •
                await self._setup_network_interceptor(page)
                
                # ê°•ì˜ í˜ì´ì§€ ì ‘ì†
                print(f"ğŸ“¡ í˜ì´ì§€ ì ‘ì† ì¤‘...")
                await page.goto(lecture_url, wait_until='domcontentloaded', timeout=self.config.TIMEOUT)
                
                # í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°
                await page.wait_for_timeout(3000)
                
                # í˜ì´ì§€ ì ‘ê·¼ ê¶Œí•œ í™•ì¸
                if await self._check_access_denied(page):
                    print("âŒ í˜ì´ì§€ ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. ë¡œê·¸ì¸ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    return []
                
                # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì˜ì—­ í™•ì¸
                has_transcript = await self._check_transcript_availability(page)
                if not has_transcript:
                    print("âš ï¸ ì´ ê°•ì˜ì—ëŠ” íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.")
                    return []
                
                print("ğŸ“œ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                
                # ìŠ¤ë§ˆíŠ¸ ìŠ¤í¬ë¡¤ë¡œ ëª¨ë“  íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ
                await self._smart_scroll_and_load(page)
                
                # 2ì´ˆ ëŒ€ê¸° (ì§€ì—° ë¡œë”© ì™„ë£Œ)
                await page.wait_for_timeout(2000)
                
                # DOMì—ì„œ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
                transcript_data = await self._extract_transcript_from_dom(page)
                
                # API ì‘ë‹µì—ì„œë„ ë°ì´í„° ì¶”ì¶œ ì‹œë„
                api_transcript_data = await self._process_api_responses()
                
                # ë‘ ì†ŒìŠ¤ì˜ ë°ì´í„° ë³‘í•© ë° ì •ì œ
                final_data = self._merge_transcript_data(transcript_data, api_transcript_data)
                
                # ê²°ê³¼ ì €ì¥
                if final_data:
                    await self._save_transcript_data(lecture_url, final_data)
                    print(f"âœ… ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(final_data)}ê°œì˜ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ")
                else:
                    print("âš ï¸ ì¶”ì¶œëœ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                return final_data
                
            except Exception as e:
                print(f"âŒ ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(f"ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}")
                return []
            finally:
                if 'browser' in locals():
                    await browser.close()
    
    def _is_valid_cokac_url(self, url: str) -> bool:
        """ì½”ë“œê¹ëŠ”ë…¸ì¸ ì‚¬ì´íŠ¸ URL ìœ íš¨ì„± ê²€ì‚¬"""
        return url.startswith(self.config.BASE_URL)
    
    async def _setup_network_interceptor(self, page: Page):
        """ë„¤íŠ¸ì›Œí¬ ì‘ë‹µ í›„í‚¹ìœ¼ë¡œ API ë°ì´í„° ìº¡ì²˜"""
        async def handle_response(response: Response):
            url = response.url
            # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸, ìë§‰, ìº¡ì…˜ ê´€ë ¨ API ì‘ë‹µ ê°ì§€
            if any(keyword in url.lower() for keyword in [
                'transcript', 'caption', 'subtitle', 'cue', 'srt', 'vtt',
                'text', 'script', 'ìë§‰', 'ìŠ¤í¬ë¦½íŠ¸'
            ]):
                try:
                    if response.ok and response.headers.get('content-type', '').startswith(('application/json', 'text/')):
                        print(f"ğŸ“¡ API ì‘ë‹µ ìº¡ì²˜: {url}")
                        
                        # JSON ì‘ë‹µ ì²˜ë¦¬
                        if 'json' in response.headers.get('content-type', ''):
                            data = await response.json()
                        else:
                            data = await response.text()
                        
                        self.api_responses.append({
                            'source': 'api',
                            'url': url,
                            'data': data,
                            'content_type': response.headers.get('content-type', ''),
                            'timestamp': datetime.now().isoformat()
                        })
                except Exception as e:
                    print(f"API ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        page.on('response', handle_response)
    
    async def _check_access_denied(self, page: Page) -> bool:
        """í˜ì´ì§€ ì ‘ê·¼ ê¶Œí•œ í™•ì¸"""
        try:
            # ì¼ë°˜ì ì¸ ì ‘ê·¼ ê±°ë¶€ íŒ¨í„´ í™•ì¸
            access_denied_indicators = [
                'ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤',
                'ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤',
                'ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤',
                'Access Denied',
                'Unauthorized',
                '403',
                '401'
            ]
            
            page_text = await page.evaluate("() => document.body.innerText")
            return any(indicator in page_text for indicator in access_denied_indicators)
            
        except Exception:
            return False
    
    async def _check_transcript_availability(self, page: Page) -> bool:
        """íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ê´€ë ¨ ìš”ì†Œ ì¡´ì¬ í™•ì¸
            transcript_selectors = [
                self.config.TRANSCRIPT_SELECTOR,
                self.config.TRANSCRIPT_CONTAINER,
                '[class*="transcript"]',
                '[class*="caption"]',
                '[class*="subtitle"]',
                '[data-testid*="transcript"]'
            ]
            
            for selector in transcript_selectors:
                element = await page.query_selector(selector)
                if element:
                    return True
            
            # í…ìŠ¤íŠ¸ ê¸°ë°˜ í™•ì¸
            page_text = await page.evaluate("() => document.body.innerText")
            transcript_keywords = ['transcript', 'ìë§‰', 'ìŠ¤í¬ë¦½íŠ¸', 'ëŒ€ë³¸']
            
            return any(keyword in page_text.lower() for keyword in transcript_keywords)
            
        except Exception:
            return True  # í™•ì¸ ì‹¤íŒ¨ ì‹œ ì‹œë„í•´ë³´ê¸°
    
    async def _smart_scroll_and_load(self, page: Page):
        """ìŠ¤ë§ˆíŠ¸ ìŠ¤í¬ë¡¤ë¡œ ì§€ì—° ë¡œë”© ì»¨í…ì¸  ëª¨ë‘ ë¡œë“œ"""
        print("ğŸ“œ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì „ì²´ ë¡œë”©ì„ ìœ„í•œ ìŠ¤ë§ˆíŠ¸ ìŠ¤í¬ë¡¤ ì‹œì‘...")
        
        scroll_script = f"""
            async () => {{
                const scrollStep = {self.config.SCROLL_STEP};
                const scrollDelay = {self.config.SCROLL_DELAY};
                const maxScrolls = {self.config.MAX_SCROLL_ATTEMPTS};
                const idleThreshold = {self.config.IDLE_THRESHOLD};
                
                // ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
                const containers = [
                    document.querySelector('{self.config.TRANSCRIPT_CONTAINER}'),
                    document.querySelector('[class*="video-player"]'),
                    document.scrollingElement,
                    document.body
                ].filter(el => el);
                
                const container = containers[0];
                
                let previousHeight = 0;
                let previousTranscriptCount = 0;
                let unchangedCount = 0;
                let scrollCount = 0;
                
                console.log('ìŠ¤í¬ë¡¤ ì‹œì‘, ì»¨í…Œì´ë„ˆ:', container?.tagName);
                
                while (unchangedCount < idleThreshold && scrollCount < maxScrolls) {{
                    // ìŠ¤í¬ë¡¤ ì‹¤í–‰
                    container.scrollBy(0, scrollStep);
                    await new Promise(resolve => setTimeout(resolve, scrollDelay));
                    
                    // ë³€í™” ê°ì§€
                    const currentHeight = container.scrollHeight || document.body.scrollHeight;
                    const currentTranscriptCount = document.querySelectorAll('{self.config.TRANSCRIPT_SELECTOR}').length;
                    
                    // ë†’ì´ë‚˜ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ê°œìˆ˜ ë³€í™” í™•ì¸
                    if (currentHeight === previousHeight && currentTranscriptCount === previousTranscriptCount) {{
                        unchangedCount++;
                    }} else {{
                        unchangedCount = 0;
                        previousHeight = currentHeight;
                        previousTranscriptCount = currentTranscriptCount;
                    }}
                    
                    scrollCount++;
                    
                    // ì§„í–‰ ìƒí™© ë¡œê·¸
                    if (scrollCount % 10 === 0) {{
                        console.log(`ìŠ¤í¬ë¡¤ ì§„í–‰: ${{scrollCount}}/${{maxScrolls}}, íŠ¸ëœìŠ¤í¬ë¦½íŠ¸: ${{currentTranscriptCount}}ê°œ`);
                    }}
                    
                    // ë§¨ ì•„ë˜ ë„ë‹¬ í™•ì¸
                    if (container.scrollTop + container.clientHeight >= container.scrollHeight - 100) {{
                        console.log('ìŠ¤í¬ë¡¤ ëì— ë„ë‹¬');
                        break;
                    }}
                }}
                
                console.log(`ìŠ¤í¬ë¡¤ ì™„ë£Œ: ì´ ${{scrollCount}}íšŒ, ìµœì¢… íŠ¸ëœìŠ¤í¬ë¦½íŠ¸: ${{previousTranscriptCount}}ê°œ`);
                return {{ scrollCount, transcriptCount: previousTranscriptCount }};
            }}
        """
        
        result = await page.evaluate(scroll_script)
        print(f"   ğŸ“Š ìŠ¤í¬ë¡¤ ê²°ê³¼: {result.get('scrollCount', 0)}íšŒ, íŠ¸ëœìŠ¤í¬ë¦½íŠ¸: {result.get('transcriptCount', 0)}ê°œ")
        
        # ìµœì¢… ì•ˆì „ ëŒ€ê¸°
        await page.wait_for_timeout(1000)
    
    async def _extract_transcript_from_dom(self, page: Page) -> List[Dict[str, Any]]:
        """DOMì—ì„œ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        print("ğŸ” DOMì—ì„œ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì¤‘...")
        
        extraction_script = f"""
            () => {{
                const transcriptElements = document.querySelectorAll('{self.config.TRANSCRIPT_SELECTOR}');
                const results = [];
                
                console.log(`íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ìš”ì†Œ ë°œê²¬: ${{transcriptElements.length}}ê°œ`);
                
                transcriptElements.forEach((element, index) => {{
                    const text = element.textContent?.trim();
                    if (text && text.length > 0) {{
                        // íƒ€ì„ìŠ¤íƒ¬í”„ ì°¾ê¸°
                        let timestamp = '';
                        let timestampElement = null;
                        
                        // ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ìš”ì†Œ ì°¾ê¸°
                        const parent = element.closest('div, li, span, article, section');
                        if (parent) {{
                            // í˜•ì œ ìš”ì†Œì—ì„œ ì°¾ê¸°
                            timestampElement = parent.querySelector('{self.config.TIMESTAMP_SELECTOR}');
                            if (!timestampElement) {{
                                // í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ì°¾ê¸°
                                timestampElement = parent.querySelector('[class*="time"], [class*="stamp"], [class*="duration"]');
                            }}
                            if (!timestampElement) {{
                                // ë°ì´í„° ì†ì„±ìœ¼ë¡œ ì°¾ê¸°
                                timestampElement = parent.querySelector('[data-time], [data-timestamp], [data-start]');
                            }}
                        }}
                        
                        if (timestampElement) {{
                            timestamp = timestampElement.textContent?.trim() || 
                                       timestampElement.getAttribute('data-time') || 
                                       timestampElement.getAttribute('data-timestamp') || '';
                        }}
                        
                        // ì¶”ê°€ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
                        const elementData = {{
                            index: index,
                            text: text,
                            timestamp: timestamp,
                            element_class: element.className || '',
                            parent_class: parent?.className || '',
                            char_length: text.length,
                            word_count: text.split(/\\s+/).length
                        }};
                        
                        results.push(elementData);
                    }}
                }});
                
                console.log(`ìœ íš¨í•œ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ: ${{results.length}}ê°œ`);
                return results;
            }}
        """
        
        transcript_data = await page.evaluate(extraction_script)
        
        print(f"   ğŸ“ DOMì—ì„œ {len(transcript_data)}ê°œì˜ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ")
        
        return transcript_data
    
    async def _process_api_responses(self) -> List[Dict[str, Any]]:
        """ìº¡ì²˜ëœ API ì‘ë‹µì—ì„œ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë°ì´í„° ì¶”ì¶œ"""
        processed_data = []
        
        for response in self.api_responses:
            try:
                data = response['data']
                
                # JSON ë°ì´í„° ì²˜ë¦¬
                if isinstance(data, dict):
                    # ì¼ë°˜ì ì¸ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ API êµ¬ì¡° ì²˜ë¦¬
                    if 'cues' in data:
                        for i, cue in enumerate(data['cues']):
                            processed_data.append({
                                'index': i,
                                'text': cue.get('text', '').strip(),
                                'timestamp': cue.get('start', '') or cue.get('time', ''),
                                'source': 'api_cues'
                            })
                    elif 'items' in data:
                        for i, item in enumerate(data['items']):
                            processed_data.append({
                                'index': i,
                                'text': item.get('text', '').strip(),
                                'timestamp': item.get('timestamp', '') or item.get('time', ''),
                                'source': 'api_items'
                            })
                    elif 'transcript' in data:
                        transcript = data['transcript']
                        if isinstance(transcript, list):
                            for i, item in enumerate(transcript):
                                processed_data.append({
                                    'index': i,
                                    'text': item.get('text', '').strip(),
                                    'timestamp': item.get('timestamp', '') or item.get('time', ''),
                                    'source': 'api_transcript'
                                })
                
                # í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ (SRT, VTT ë“±)
                elif isinstance(data, str):
                    if '.srt' in response['url'] or 'WEBVTT' in data:
                        parsed = self._parse_subtitle_format(data)
                        processed_data.extend(parsed)
                        
            except Exception as e:
                print(f"API ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        print(f"   ğŸŒ APIì—ì„œ {len(processed_data)}ê°œì˜ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ")
        return processed_data
    
    def _parse_subtitle_format(self, content: str) -> List[Dict[str, Any]]:
        """SRT, VTT ë“± ìë§‰ í˜•ì‹ íŒŒì‹±"""
        results = []
        
        # SRT í˜•ì‹ íŒŒì‹±
        if '-->' in content:
            blocks = re.split(r'\n\s*\n', content.strip())
            for i, block in enumerate(blocks):
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    # íƒ€ì„ìŠ¤íƒ¬í”„ ë¼ì¸ ì°¾ê¸°
                    timestamp_line = None
                    text_lines = []
                    
                    for line in lines:
                        if '-->' in line:
                            timestamp_line = line
                        elif line.strip() and not line.strip().isdigit():
                            text_lines.append(line.strip())
                    
                    if timestamp_line and text_lines:
                        results.append({
                            'index': i,
                            'text': ' '.join(text_lines),
                            'timestamp': timestamp_line.split('-->')[0].strip(),
                            'source': 'subtitle_file'
                        })
        
        return results
    
    def _merge_transcript_data(self, dom_data: List[Dict], api_data: List[Dict]) -> List[Dict[str, Any]]:
        """DOMê³¼ APIì—ì„œ ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ë³‘í•©í•˜ê³  ì •ì œ"""
        
        # DOM ë°ì´í„°ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        merged_data = dom_data.copy()
        
        # API ë°ì´í„°ê°€ ë” ë§ê±°ë‚˜ ë” ì •í™•í•˜ë‹¤ë©´ êµì²´
        if len(api_data) > len(dom_data) * 1.1:  # 10% ì´ìƒ ë§ìœ¼ë©´
            print("   ğŸ”„ API ë°ì´í„°ê°€ ë” í’ë¶€í•˜ì—¬ API ë°ì´í„°ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            merged_data = api_data
            
            # DOM ë°ì´í„°ì˜ ìœ ìš©í•œ ì •ë³´ ë³‘í•©
            for dom_item in dom_data:
                matching_api_item = None
                for api_item in api_data:
                    if self._is_similar_text(dom_item['text'], api_item['text']):
                        matching_api_item = api_item
                        break
                
                if matching_api_item:
                    # ë” ë‚˜ì€ ì •ë³´ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
                    if not matching_api_item.get('timestamp') and dom_item.get('timestamp'):
                        matching_api_item['timestamp'] = dom_item['timestamp']
        
        # ì¤‘ë³µ ì œê±° ë° ì •ì œ
        unique_data = []
        seen_texts = set()
        
        for item in merged_data:
            text = item['text'].strip()
            if text and text not in seen_texts and len(text) > 5:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
                seen_texts.add(text)
                
                # ë°ì´í„° ì •ì œ
                cleaned_item = {
                    'index': len(unique_data),
                    'text': text,
                    'timestamp': self._format_timestamp(item.get('timestamp', '')),
                    'source': item.get('source', 'dom'),
                    'length': len(text),
                    'word_count': len(text.split())
                }
                
                unique_data.append(cleaned_item)
        
        # ì¸ë±ìŠ¤ ìˆœì„œë¡œ ì •ë ¬ (ê°€ëŠ¥í•œ ê²½ìš°)
        try:
            unique_data.sort(key=lambda x: x.get('original_index', x['index']))
        except:
            pass
        
        print(f"   ğŸ”§ ë°ì´í„° ì •ì œ ì™„ë£Œ: {len(merged_data)} â†’ {len(unique_data)}ê°œ")
        return unique_data
    
    def _is_similar_text(self, text1: str, text2: str, threshold: float = 0.8) -> bool:
        """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ì„± íŒë‹¨"""
        if not text1 or not text2:
            return False
        
        # ê°„ë‹¨í•œ ìœ ì‚¬ì„± ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© ê°€ëŠ¥)
        text1_clean = re.sub(r'[^\w\s]', '', text1.lower())
        text2_clean = re.sub(r'[^\w\s]', '', text2.lower())
        
        if text1_clean == text2_clean:
            return True
        
        # ë¶€ë¶„ ë¬¸ìì—´ í¬í•¨ ê´€ê³„ í™•ì¸
        if len(text1_clean) > len(text2_clean):
            return text2_clean in text1_clean
        else:
            return text1_clean in text2_clean
    
    def _format_timestamp(self, timestamp: str) -> str:
        """íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ í†µì¼"""
        if not timestamp:
            return ""
        
        # ë‹¤ì–‘í•œ íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ì„ í†µì¼ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        timestamp = timestamp.strip()
        
        # ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if re.match(r'^\d{1,2}:\d{2}(:\d{2})?$', timestamp):
            return timestamp
        
        # ì´ˆ ë‹¨ìœ„ ìˆ«ìë¥¼ ì‹œ:ë¶„:ì´ˆë¡œ ë³€í™˜
        if timestamp.replace('.', '').isdigit():
            try:
                seconds = float(timestamp)
                minutes = int(seconds // 60)
                seconds = int(seconds % 60)
                return f"{minutes:02d}:{seconds:02d}"
            except:
                pass
        
        return timestamp
    
    async def _save_transcript_data(self, lecture_url: str, transcript_data: List[Dict[str, Any]]):
        """íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.config.OUTPUT_PATH, exist_ok=True)
        
        # íŒŒì¼ëª… ìƒì„± (URLì—ì„œ ê°•ì˜ ID ì¶”ì¶œ)
        lecture_id = self._extract_lecture_id(lecture_url)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # JSON í˜•íƒœë¡œ ì €ì¥
        json_filename = f"{self.config.OUTPUT_PATH}/transcript_{lecture_id}_{timestamp}.json"
        json_data = {
            'lecture_url': lecture_url,
            'lecture_id': lecture_id,
            'scraped_at': datetime.now().isoformat(),
            'transcript_count': len(transcript_data),
            'total_characters': sum(item['length'] for item in transcript_data),
            'total_words': sum(item['word_count'] for item in transcript_data),
            'sources_used': list(set(item['source'] for item in transcript_data)),
            'transcripts': transcript_data,
            'raw_api_responses': len(self.api_responses),
            'config_used': {
                'headless': self.config.HEADLESS,
                'timeout': self.config.TIMEOUT,
                'scroll_delay': self.config.SCROLL_DELAY
            }
        }
        
        async with aiofiles.open(json_filename, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(json_data, ensure_ascii=False, indent=2))
        
        # ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ í˜•íƒœë¡œë„ ì €ì¥
        txt_filename = f"{self.config.OUTPUT_PATH}/transcript_{lecture_id}_{timestamp}.txt"
        async with aiofiles.open(txt_filename, 'w', encoding='utf-8') as f:
            await f.write(f"ê°•ì˜ URL: {lecture_url}\n")
            await f.write(f"ê°•ì˜ ID: {lecture_id}\n")
            await f.write(f"ìŠ¤í¬ë˜í•‘ ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}\n")
            await f.write(f"ì´ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸: {len(transcript_data)}ê°œ\n")
            await f.write(f"ì´ ê¸€ì ìˆ˜: {sum(item['length'] for item in transcript_data):,}ì\n")
            await f.write(f"ì´ ë‹¨ì–´ ìˆ˜: {sum(item['word_count'] for item in transcript_data):,}ê°œ\n")
            await f.write("=" * 80 + "\n\n")
            
            for i, item in enumerate(transcript_data, 1):
                timestamp_str = f"[{item['timestamp']}] " if item['timestamp'] else ""
                line = f"{i:3d}. {timestamp_str}{item['text']}\n"
                await f.write(line)
                
                # ê¸´ í…ìŠ¤íŠ¸ì¸ ê²½ìš° ì¤„ë°”ê¿ˆ ì¶”ê°€
                if item['length'] > 100:
                    await f.write("\n")
        
        print(f"ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ:")
        print(f"   ğŸ“„ JSON: {json_filename}")
        print(f"   ğŸ“ TXT: {txt_filename}")
        print(f"   ğŸ“Š ì´ {len(transcript_data)}ê°œ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸, {sum(item['length'] for item in transcript_data):,}ì")
    
    def _extract_lecture_id(self, url: str) -> str:
        """URLì—ì„œ ê°•ì˜ ID ì¶”ì¶œ"""
        # URLì—ì„œ ìˆ«ì ID íŒ¨í„´ ì¶”ì¶œ
        match = re.search(r'/(\w+/)?(\d+)/?$', url)
        if match:
            return match.group(2)
        
        # ëŒ€ì²´ íŒ¨í„´ë“¤
        patterns = [
            r'/lec\w*(\d+)',
            r'/lecture[/_](\d+)',
            r'/course[/_](\d+)',
            r'[/_](\d+)/?$'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        # IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ URLì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ìš©
        return url.split('/')[-1] or 'unknown'

