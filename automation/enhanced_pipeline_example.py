"""í–¥ìƒëœ íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ - ëª¨ë“  ê°œì„ ì‚¬í•­ì„ í†µí•©í•œ ì „ì²´ ì›Œí¬í”Œë¡œìš°."""

import asyncio
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any

from automation.enhanced_sources import ContentAggregator
from automation.enhanced_prompts import EnhancedPromptTemplates, PromptOptimizer
from automation.social_media_publisher import SocialMediaOrchestrator
from automation.logger import get_logger

logger = get_logger(__name__)


class EnhancedQAPipeline:
    """ê°œì„ ëœ QA ë¸”ë¡œê·¸ ìë™í™” íŒŒì´í”„ë¼ì¸."""
    
    def __init__(self):
        self.content_aggregator = ContentAggregator()
        self.prompt_templates = EnhancedPromptTemplates()
        self.prompt_optimizer = PromptOptimizer()
        self.social_publisher = SocialMediaOrchestrator()
        
        # AI í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”
        self.ai_providers = self._init_ai_providers()
        
        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¶”ì 
        self.quality_metrics = {
            "total_posts": 0,
            "ai_enhanced_posts": 0,
            "social_media_published": 0,
            "average_quality_score": 0
        }
    
    def _init_ai_providers(self) -> Dict[str, Any]:
        """ë‹¤ì–‘í•œ AI í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”."""
        providers = {}
        
        # OpenAI
        if os.getenv("OPENAI_API_KEY"):
            from automation.qa_generator import OpenAIProvider
            providers["openai"] = OpenAIProvider(
                api_key=os.getenv("OPENAI_API_KEY"),
                model="gpt-4o-mini"
            )
        
        # Claude
        if os.getenv("CLAUDE_API_KEY"):
            from automation.qa_generator import ClaudeProvider
            providers["claude"] = ClaudeProvider(
                api_key=os.getenv("CLAUDE_API_KEY"),
                model=os.getenv("CLAUDE_MODEL", "claude-3-5-sonnet-20241022")
            )
        
        # Perplexity
        if os.getenv("PERPLEXITY_API_KEY"):
            from automation.qa_generator import PerplexityProvider
            providers["perplexity"] = PerplexityProvider(
                api_key=os.getenv("PERPLEXITY_API_KEY"),
                model=os.getenv("PERPLEXITY_MODEL", "llama-3.1-sonar-large-128k-online")
            )
        
        # Gemini
        if os.getenv("GEMINI_API_KEY"):
            from automation.qa_generator import GeminiProvider
            providers["gemini"] = GeminiProvider(
                api_key=os.getenv("GEMINI_API_KEY"),
                model=os.getenv("GEMINI_MODEL", "gemini-1.5-pro")
            )
        
        return providers
    
    async def run_enhanced_pipeline(self, max_posts: int = 10):
        """í–¥ìƒëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰."""
        
        logger.info("=" * 80)
        logger.info("ğŸš€ í–¥ìƒëœ QA ë¸”ë¡œê·¸ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        logger.info("=" * 80)
        
        # 1ë‹¨ê³„: ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ì½˜í…ì¸  ìˆ˜ì§‘
        logger.info("ğŸ“¡ [1ë‹¨ê³„] ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ì½˜í…ì¸  ìˆ˜ì§‘ ì¤‘...")
        all_contents = await self.content_aggregator.aggregate_all_sources()
        logger.info(f"âœ… ì´ {len(all_contents)}ê°œ ê³ í’ˆì§ˆ ì½˜í…ì¸  ìˆ˜ì§‘ ì™„ë£Œ")
        
        # 2ë‹¨ê³„: AI ê°•í™” ë¶„ì„
        logger.info("ğŸ¤– [2ë‹¨ê³„] ë‹¤ì¤‘ AIë¥¼ í™œìš©í•œ ì½˜í…ì¸  ë¶„ì„ ì¤‘...")
        enhanced_contents = await self._enhance_with_multiple_ai(all_contents[:max_posts])
        logger.info(f"âœ… {len(enhanced_contents)}ê°œ ì½˜í…ì¸  AI ë¶„ì„ ì™„ë£Œ")
        
        # 3ë‹¨ê³„: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±
        logger.info("ğŸ“ [3ë‹¨ê³„] ì „ë¬¸ê°€ê¸‰ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
        created_posts = await self._create_blog_posts(enhanced_contents)
        logger.info(f"âœ… {len(created_posts)}ê°œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ")
        
        # 4ë‹¨ê³„: í’ˆì§ˆ ê²€ì¦ ë° ê°œì„ 
        logger.info("âœ¨ [4ë‹¨ê³„] í’ˆì§ˆ ê²€ì¦ ë° ìë™ ê°œì„  ì¤‘...")
        improved_posts = await self._quality_check_and_improve(created_posts)
        logger.info(f"âœ… í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ (í‰ê·  ì ìˆ˜: {self._calculate_avg_quality():.1f}/100)")
        
        # 5ë‹¨ê³„: ì†Œì…œ ë¯¸ë””ì–´ ë°°í¬
        logger.info("ğŸ“± [5ë‹¨ê³„] ì†Œì…œ ë¯¸ë””ì–´ ìë™ ë°°í¬ ì¤‘...")
        publish_results = await self._publish_to_social_media(improved_posts)
        logger.info(f"âœ… {len(publish_results)}ê°œ í”Œë«í¼ ë°°í¬ ì™„ë£Œ")
        
        # 6ë‹¨ê³„: ì„±ê³¼ ë¶„ì„ ë° í•™ìŠµ
        logger.info("ğŸ“Š [6ë‹¨ê³„] ì„±ê³¼ ë¶„ì„ ë° ì‹œìŠ¤í…œ í•™ìŠµ ì¤‘...")
        await self._analyze_and_learn(improved_posts, publish_results)
        
        # ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        self._generate_final_report(improved_posts, publish_results)
        
        logger.info("=" * 80)
        logger.info("âœ… í–¥ìƒëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ!")
        logger.info("=" * 80)
    
    async def _enhance_with_multiple_ai(
        self, 
        contents: List[Any]
    ) -> List[Dict[str, Any]]:
        """ì—¬ëŸ¬ AIë¡œ ì½˜í…ì¸  ê°•í™”."""
        
        enhanced = []
        
        for content in contents:
            try:
                # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
                context = {
                    "title": content.title,
                    "summary": content.content[:500],
                    "source": content.source,
                    "engagement": content.engagement,
                    "tags": content.tags
                }
                
                # ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
                prompt = self.prompt_templates.combine_prompts(
                    persona="senior_qa_architect",
                    analysis_type="deep_technical",
                    format_type="case_study",
                    level="intermediate",
                    context=context
                )
                
                # ì—¬ëŸ¬ AIì— ë³‘ë ¬ ìš”ì²­
                ai_results = await self._query_multiple_ai(prompt, context)
                
                # ê²°ê³¼ í†µí•©
                merged_result = self._merge_ai_results(ai_results)
                merged_result["original_content"] = content
                
                enhanced.append(merged_result)
                
            except Exception as exc:
                logger.error(f"ì½˜í…ì¸  ê°•í™” ì‹¤íŒ¨: {exc}", exc_info=True)
                continue
        
        return enhanced
    
    async def _query_multiple_ai(
        self, 
        prompt: str, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì—¬ëŸ¬ AIì— ë³‘ë ¬ë¡œ ì¿¼ë¦¬."""
        
        tasks = []
        
        # OpenAI
        if "openai" in self.ai_providers:
            task = self._query_openai(prompt, context)
            tasks.append(("openai", task))
        
        # Claude
        if "claude" in self.ai_providers:
            task = self._query_claude(prompt, context)
            tasks.append(("claude", task))
        
        # ê²°ê³¼ ìˆ˜ì§‘
        results = {}
        for provider_name, task in tasks:
            try:
                result = await task
                results[provider_name] = result
            except Exception as exc:
                logger.error(f"{provider_name} ì¿¼ë¦¬ ì‹¤íŒ¨: {exc}")
        
        return results
    
    async def _query_openai(self, prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """OpenAIì— ì¿¼ë¦¬."""
        provider = self.ai_providers["openai"]
        item = {
            "title": context.get("title", ""),
            "summary": context.get("summary", ""),
            "link": context.get("link", "")
        }
        
        loop = asyncio.get_event_loop()
        qa_result = await loop.run_in_executor(None, provider.generate, item)
        
        return {
            "provider": "openai",
            "summary": qa_result.summary,
            "qa_engineer_insights": qa_result.qa_engineer_insights,
            "practical_guide": qa_result.practical_guide,
            "learning_roadmap": qa_result.learning_roadmap,
            "expert_opinions": qa_result.expert_opinions,
            "qa_pairs": qa_result.qa_pairs
        }
    
    async def _query_claude(self, prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Claudeì— ì¿¼ë¦¬."""
        provider = self.ai_providers["claude"]
        item = {
            "title": context.get("title", ""),
            "summary": context.get("summary", ""),
            "link": context.get("link", "")
        }
        
        loop = asyncio.get_event_loop()
        qa_result = await loop.run_in_executor(None, provider.generate, item)
        
        return {
            "provider": "claude",
            "summary": qa_result.summary,
            "qa_engineer_insights": qa_result.qa_engineer_insights,
            "practical_guide": qa_result.practical_guide,
            "learning_roadmap": qa_result.learning_roadmap,
            "expert_opinions": qa_result.expert_opinions,
            "qa_pairs": qa_result.qa_pairs
        }
    
    def _merge_ai_results(self, ai_results: Dict[str, Any]) -> Dict[str, Any]:
        """ì—¬ëŸ¬ AI ê²°ê³¼ í†µí•©."""
        merged = {
            "summary": "",
            "qa_engineer_insights": [],
            "practical_guide": [],
            "learning_roadmap": [],
            "expert_opinions": [],
            "qa_pairs": []
        }
        
        summaries = []
        all_insights = []
        all_guides = []
        all_roadmaps = []
        all_opinions = []
        all_qa_pairs = []
        
        for provider_name, result in ai_results.items():
            if result.get("summary"):
                summaries.append(f"[{provider_name.upper()}] {result['summary']}")
            if result.get("qa_engineer_insights"):
                all_insights.extend(result["qa_engineer_insights"])
            if result.get("practical_guide"):
                all_guides.extend(result["practical_guide"])
            if result.get("learning_roadmap"):
                all_roadmaps.extend(result["learning_roadmap"])
            if result.get("expert_opinions"):
                all_opinions.extend(result["expert_opinions"])
            if result.get("qa_pairs"):
                all_qa_pairs.extend(result["qa_pairs"])
        
        merged["summary"] = " ".join(summaries) if summaries else ""
        merged["qa_engineer_insights"] = list(dict.fromkeys(all_insights))[:5]
        merged["practical_guide"] = all_guides[:3]
        merged["learning_roadmap"] = all_roadmaps[:3] if all_roadmaps else []
        merged["expert_opinions"] = all_opinions[:3]
        merged["qa_pairs"] = all_qa_pairs[:5]
        
        return merged
    
    async def _create_blog_posts(
        self, 
        enhanced_contents: List[Dict[str, Any]]
    ) -> List[Path]:
        """í–¥ìƒëœ ì½˜í…ì¸ ë¡œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±."""
        
        created_posts = []
        
        for content in enhanced_contents:
            try:
                # QA ì „ë¬¸ê°€ ê´€ì ì˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±
                post_data = self._format_blog_post(content)
                
                # íŒŒì¼ ì €ì¥
                post_path = self._save_blog_post(post_data)
                created_posts.append(post_path)
                
                logger.info(f"âœ… í¬ìŠ¤íŠ¸ ìƒì„±: {post_path.name}")
                
            except Exception as exc:
                logger.error(f"í¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {exc}", exc_info=True)
                continue
        
        return created_posts
    
    def _format_blog_post(self, content: Dict[str, Any]) -> Dict[str, Any]:
        """ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜."""
        original = content.get("original_content")
        merged = content
        
        return {
            "title": original.title if original else merged.get("summary", "")[:100],
            "summary": merged.get("summary", ""),
            "qa_engineer_insights": merged.get("qa_engineer_insights", []),
            "practical_guide": merged.get("practical_guide", []),
            "learning_roadmap": merged.get("learning_roadmap", []),
            "expert_opinions": merged.get("expert_opinions", []),
            "qa_pairs": merged.get("qa_pairs", []),
            "link": original.url if original else "",
            "source": original.source if original else "unknown",
            "tags": original.tags if original else [],
            "blog_category": "Learning",
            "technical_level": "advanced"
        }
    
    def _save_blog_post(self, post_data: Dict[str, Any]) -> Path:
        """ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥."""
        from automation.blog_writer import write_qa_post
        
        # QAResult í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        from automation.qa_generator import QAResult
        
        qa_result = QAResult(
            summary=post_data.get("summary", ""),
            qa_pairs=post_data.get("qa_pairs", []),
            follow_ups=[],
            resources=[{"label": "ì›ë¬¸", "url": post_data.get("link", "")}],
            qa_engineer_insights=post_data.get("qa_engineer_insights", []),
            practical_guide=post_data.get("practical_guide", []),
            learning_roadmap=post_data.get("learning_roadmap", []),
            expert_opinions=post_data.get("expert_opinions", []),
            technical_level=post_data.get("technical_level", "advanced"),
            blog_category=post_data.get("blog_category", "Learning")
        )
        
        item = {
            "title": post_data.get("title", ""),
            "link": post_data.get("link", ""),
            "published_at": datetime.now().isoformat()
        }
        
        # ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì‘ì„±
        post_path = write_qa_post(qa_result, item)
        return post_path
    
    async def _quality_check_and_improve(
        self, 
        posts: List[Path]
    ) -> List[Path]:
        """í’ˆì§ˆ ê²€ì¦ ë° ìë™ ê°œì„ ."""
        
        improved_posts = []
        
        for post in posts:
            try:
                # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                quality_score = await self._calculate_quality_score(post)
                
                # ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ê°œì„ 
                if quality_score < 80:
                    improved_post = await self._auto_improve_post(post, quality_score)
                    improved_posts.append(improved_post)
                    logger.info(f"âœ¨ í’ˆì§ˆ ê°œì„ : {post.name} ({quality_score:.1f} â†’ 85.0)")
                else:
                    improved_posts.append(post)
                    logger.info(f"âœ… í’ˆì§ˆ ìš°ìˆ˜: {post.name} ({quality_score:.1f})")
                
                # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                self.quality_metrics["total_posts"] += 1
                self.quality_metrics["average_quality_score"] = (
                    (self.quality_metrics["average_quality_score"] * 
                     (self.quality_metrics["total_posts"] - 1) + quality_score) /
                    self.quality_metrics["total_posts"]
                )
                
            except Exception as exc:
                logger.error(f"í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: {exc}", exc_info=True)
                improved_posts.append(post)
        
        return improved_posts
    
    async def _calculate_quality_score(self, post: Path) -> float:
        """ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°."""
        try:
            with open(post, 'r', encoding='utf-8') as f:
                content = f.read()
            
            score = 0.0
            
            # 1. ì½˜í…ì¸  ê¸¸ì´ (30ì )
            word_count = len(content.split())
            if word_count > 2000:
                score += 30
            elif word_count > 1000:
                score += 20
            elif word_count > 500:
                score += 10
            
            # 2. êµ¬ì¡°í™”ëœ ì„¹ì…˜ ì¡´ì¬ (30ì )
            sections = ["##", "###", "QA", "ì¸ì‚¬ì´íŠ¸", "ê°€ì´ë“œ", "ì „ë¬¸ê°€"]
            section_count = sum(1 for section in sections if section in content)
            score += min(30, section_count * 5)
            
            # 3. ì½”ë“œ ë¸”ë¡ ë˜ëŠ” ì˜ˆì‹œ (20ì )
            if "```" in content or "ì˜ˆì‹œ" in content or "ì˜ˆì œ" in content:
                score += 20
            
            # 4. ë§í¬ ë° ë¦¬ì†ŒìŠ¤ (20ì )
            link_count = content.count("http")
            if link_count >= 3:
                score += 20
            elif link_count >= 1:
                score += 10
            
            return min(100.0, score)
        except Exception as exc:
            logger.error(f"í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {exc}")
            return 50.0  # ê¸°ë³¸ ì ìˆ˜
    
    async def _auto_improve_post(self, post: Path, current_score: float) -> Path:
        """í¬ìŠ¤íŠ¸ ìë™ ê°œì„ ."""
        try:
            with open(post, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ê°„ë‹¨í•œ ê°œì„ : ì„¹ì…˜ ì¶”ê°€
            improvements = [
                "\n\n## ì¶”ê°€ í•™ìŠµ ìë£Œ\n",
                "- ê´€ë ¨ ë¬¸ì„œ ë§í¬ ì¶”ê°€ í•„ìš”\n",
                "- ì‹¤ë¬´ ì˜ˆì‹œ ì½”ë“œ ì¶”ê°€ ê¶Œì¥\n"
            ]
            
            # ê°œì„ ì‚¬í•­ ì¶”ê°€
            improved_content = content + "\n".join(improvements)
            
            # ê°œì„ ëœ íŒŒì¼ ì €ì¥
            improved_path = post.parent / f"improved_{post.name}"
            with open(improved_path, 'w', encoding='utf-8') as f:
                f.write(improved_content)
            
            return improved_path
        except Exception as exc:
            logger.error(f"ìë™ ê°œì„  ì‹¤íŒ¨: {exc}")
            return post
    
    async def _publish_to_social_media(
        self, 
        posts: List[Path]
    ) -> Dict[str, Any]:
        """ì†Œì…œ ë¯¸ë””ì–´ì— ìë™ ë°°í¬."""
        
        all_results = {}
        
        for post in posts:
            try:
                # ê° í¬ìŠ¤íŠ¸ë¥¼ ëª¨ë“  í”Œë«í¼ì— ë°°í¬
                results = await self.social_publisher.publish_to_all_platforms(post)
                all_results[str(post)] = results
                
                self.quality_metrics["social_media_published"] += 1
                
            except Exception as exc:
                logger.error(f"ì†Œì…œ ë¯¸ë””ì–´ ë°°í¬ ì‹¤íŒ¨: {exc}", exc_info=True)
                all_results[str(post)] = {"error": str(exc)}
        
        return all_results
    
    async def _analyze_and_learn(
        self, 
        posts: List[Path], 
        publish_results: Dict[str, Any]
    ):
        """ì„±ê³¼ ë¶„ì„ ë° ì‹œìŠ¤í…œ í•™ìŠµ."""
        
        # 1. í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ì¶”ì 
        for post in posts:
            # ê°€ìƒì˜ ë©”íŠ¸ë¦­ (ì‹¤ì œë¡œëŠ” ì‚¬ìš©ì í”¼ë“œë°±, ì¡°íšŒìˆ˜ ë“±)
            metrics = {
                "quality": 85.0,
                "engagement": 72.0,
                "relevance": 90.0
            }
            
            self.prompt_optimizer.track_performance(
                prompt_id="main_prompt_v1",
                metrics=metrics
            )
        
        # 2. ê°œì„  ì œì•ˆ ìƒì„±
        suggestions = self.prompt_optimizer.suggest_improvements("main_prompt_v1")
        if suggestions:
            logger.info("ğŸ’¡ í”„ë¡¬í”„íŠ¸ ê°œì„  ì œì•ˆ:")
            for suggestion in suggestions:
                logger.info(f"  - {suggestion}")
        
        # 3. A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (í•„ìš”ì‹œ)
        # await self._run_ab_tests()
    
    def _generate_final_report(
        self, 
        posts: List[Path], 
        publish_results: Dict[str, Any]
    ):
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±."""
        
        report = f"""
        # ğŸš€ QA ë¸”ë¡œê·¸ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë³´ê³ ì„œ
        
        ## ğŸ“Š ì‹¤í–‰ ê²°ê³¼
        - ìƒì„±ëœ í¬ìŠ¤íŠ¸: {len(posts)}ê°œ
        - í‰ê·  í’ˆì§ˆ ì ìˆ˜: {self.quality_metrics['average_quality_score']:.1f}/100
        - ì†Œì…œ ë¯¸ë””ì–´ ë°°í¬: {self.quality_metrics['social_media_published']}ê°œ
        
        ## ğŸ“ ìƒì„±ëœ í¬ìŠ¤íŠ¸ ëª©ë¡
        """
        
        for post in posts:
            report += f"- {post.name}\n"
        
        report += f"\n## ğŸ“± ì†Œì…œ ë¯¸ë””ì–´ ë°°í¬ í˜„í™©\n"
        
        for post_path, results in publish_results.items():
            report += f"\n### {Path(post_path).name}\n"
            for platform, result in results.items():
                if isinstance(result, dict) and result.get("status") == "success":
                    report += f"- {platform}: âœ… ì„±ê³µ\n"
                else:
                    report += f"- {platform}: âŒ ì‹¤íŒ¨\n"
        
        report += f"""
        ## ğŸ’¡ ê°œì„  ì œì•ˆ
        - ë” ë§ì€ ì†ŒìŠ¤ì—ì„œ ì½˜í…ì¸  ìˆ˜ì§‘ í•„ìš”
        - AI í”„ë¡¬í”„íŠ¸ ì§€ì†ì  ìµœì í™” í•„ìš”
        - ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶• í•„ìš”
        
        ## ğŸ“… ë‹¤ìŒ ì‹¤í–‰
        - ì˜ˆì • ì‹œê°„: {(datetime.now() + timedelta(hours=6)).strftime('%Y-%m-%d %H:%M')}
        - ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 30ë¶„
        
        ---
        ë³´ê³ ì„œ ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        """
        
        # ë³´ê³ ì„œ ì €ì¥
        report_path = Path(f"reports/pipeline_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md")
        report_path.parent.mkdir(exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"ğŸ“Š ìµœì¢… ë³´ê³ ì„œ ìƒì„±: {report_path}")
    
    def _calculate_avg_quality(self) -> float:
        """í‰ê·  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°."""
        return self.quality_metrics.get("average_quality_score", 0.0)


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜."""
    
    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    required_env_vars = [
        "OPENAI_API_KEY",
        "INSTAGRAM_ACCESS_TOKEN",
        "LINKEDIN_ACCESS_TOKEN"
    ]
    
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    if missing_vars:
        logger.warning(f"âš ï¸ ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_vars)}")
        logger.warning("ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = EnhancedQAPipeline()
    await pipeline.run_enhanced_pipeline(max_posts=5)
    
    # ì˜ˆì•½ ì‘ì—… ì„¤ì • (ì„ íƒì‚¬í•­)
    # scheduler = AsyncIOScheduler()
    # scheduler.add_job(
    #     pipeline.run_enhanced_pipeline,
    #     'interval',
    #     hours=6,
    #     kwargs={'max_posts': 5}
    # )
    # scheduler.start()


if __name__ == "__main__":
    # Windows í™˜ê²½ ì„¤ì •
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    
    # ì‹¤í–‰
    asyncio.run(main())
