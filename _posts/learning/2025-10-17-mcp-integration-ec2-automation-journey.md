---
layout: post
title: "MCP Sequential Thinkingì„ í™œìš©í•œ ë¸”ë¡œê·¸ ìë™í™” ì‹œìŠ¤í…œ êµ¬ì¶•ê¸°: ë¬¸ì œ ì¸ì‹ë¶€í„° EC2 ë°°í¬ê¹Œì§€"
date: 2025-10-17 23:00:00 +0900
categories: [Learning]
tags: [MCP, Model Context Protocol, AI, Automation, EC2, AWS, Python, Node.js, DevOps, Sequential Thinking, System Design]
summary: "GeekNews ìë™í™” ì‹œìŠ¤í…œì— MCP Sequential Thinkingì„ í†µí•©í•˜ê³  EC2ì— ë°°í¬í•˜ê¸°ê¹Œì§€ì˜ ì „ì²´ ì—¬ì •. ë¬¸ì œ ì¸ì‹, ê¸°ìˆ  ì„ íƒ, ì•„í‚¤í…ì²˜ ì„¤ê³„, êµ¬í˜„ ê³¼ì •, ê·¸ë¦¬ê³  ë°°ìš´ ì ì„ ìƒì„¸íˆ ê¸°ë¡í•©ë‹ˆë‹¤."
original_url: "https://github.com/modelcontextprotocol/servers"
---

## ë“¤ì–´ê°€ë©°

ì´ ê¸€ì€ ë‹¨ìˆœí•œ ê¸°ìˆ  ë¬¸ì„œê°€ ì•„ë‹™ë‹ˆë‹¤.

í•˜ë‚˜ì˜ ì•„ì´ë””ì–´ê°€ ì™„ì „í•œ ì‹œìŠ¤í…œìœ¼ë¡œ ë°œì „í•˜ê¸°ê¹Œì§€ì˜ **ì‚¬ê³  ê³¼ì •**, **ê¸°ìˆ ì  ì˜ì‚¬ê²°ì •**, **ì‹¤ì œ êµ¬í˜„**, ê·¸ë¦¬ê³  **ë°°ìš´ êµí›ˆ**ì„ ë‹´ì€ ì—”ì§€ë‹ˆì–´ë§ ì¼ì§€ì…ë‹ˆë‹¤.

**í•µì‹¬ ì§ˆë¬¸:**
> "ê¸°ìˆ  ê¸°ì‚¬ë¥¼ ë¶„ì„í•  ë•Œ AIê°€ ë” ê¹Šì´ ìˆê²Œ, ë‹¨ê³„ì ìœ¼ë¡œ ìƒê°í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìˆì„ê¹Œ?"

ì´ ì§ˆë¬¸ìœ¼ë¡œë¶€í„° ì‹œì‘ëœ í”„ë¡œì íŠ¸ê°€ ì–´ë–»ê²Œ MCP(Model Context Protocol) í†µí•©, GitHub ìë™í™”, ê·¸ë¦¬ê³  EC2 ë¬´ì¸ ë°°í¬ ì‹œìŠ¤í…œìœ¼ë¡œ ë°œì „í–ˆëŠ”ì§€ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.

---

## 1. ë¬¸ì œ ì¸ì‹: ì™œ ì´ë ‡ê²Œ ìƒê°í–ˆëŠ”ê°€?

### 1.1 ì´ˆê¸° ìƒí™© ë¶„ì„

ì €ëŠ” ì´ë¯¸ GeekNews ê¸°ì‚¬ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³  OpenAI APIë¡œ QA í˜•ì‹ì˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œì„ ìš´ì˜í•˜ê³  ìˆì—ˆìŠµë‹ˆë‹¤.

**ê¸°ì¡´ ì‹œìŠ¤í…œ êµ¬ì¡°:**
```
GeekNews RSS Feed
    â†“
Python ìŠ¤í¬ë¦½íŠ¸ (RSS íŒŒì‹±)
    â†“
OpenAI API (GPT-4o-mini)
    â†“
Jekyll ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±
    â†“
ìˆ˜ë™ Git Push
```

**ì‘ë™ í˜„í™©:**
- ë§¤ì¼ ìˆ˜ë™ ì‹¤í–‰
- 5-10ê°œ í¬ìŠ¤íŠ¸ ìƒì„±
- OpenAI ë¹„ìš©: ì•½ $2-3/ì¼

### 1.2 ë°œê²¬í•œ 3ê°€ì§€ ë¬¸ì œì 

#### ë¬¸ì œ 1: ë‹¨í¸ì ì¸ AI ë¶„ì„

```python
# ê¸°ì¡´ í”„ë¡¬í”„íŠ¸
prompt = f"""
ì´ ê¸°ì‚¬ë¥¼ QA Engineer ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”:
ì œëª©: {title}
ìš”ì•½: {summary}
"""
```

**ë¬¸ì œì :**
- AIê°€ ê²°ê³¼ë§Œ ì œì‹œí•˜ê³  **ì‚¬ê³  ê³¼ì •ì´ ë³´ì´ì§€ ì•ŠìŒ**
- "AëŠ” Bì´ë‹¤"ë¼ê³  ë§í•˜ì§€ë§Œ, "ì™œ ê·¸ë ‡ê²Œ ìƒê°í–ˆëŠ”ì§€" ì•Œ ìˆ˜ ì—†ìŒ
- ë³µì¡í•œ ê¸°ìˆ  ê¸°ì‚¬ì¼ìˆ˜ë¡ ë¶„ì„ì˜ ê¹Šì´ê°€ ë¶€ì¡±

**ì‹¤ì œ ì˜ˆì‹œ:**
```
ì…ë ¥: "Kubernetes 1.29ì—ì„œ ìƒˆë¡œìš´ ìŠ¤ì¼€ì¤„ëŸ¬ ê¸°ëŠ¥ ì¶”ê°€"

ê¸°ì¡´ ì¶œë ¥:
"QA ê´€ì ì—ì„œ ìŠ¤ì¼€ì¼ë§ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤."

ì›í–ˆë˜ ì¶œë ¥:
"1ë‹¨ê³„: ìŠ¤ì¼€ì¤„ëŸ¬ ë³€ê²½ì´ ê¸°ì¡´ ì›Œí¬ë¡œë“œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ íŒŒì•…
 2ë‹¨ê³„: ìƒˆë¡œìš´ ìŠ¤ì¼€ì¤„ë§ ì •ì±…ì˜ ì—£ì§€ ì¼€ì´ìŠ¤ ì‹ë³„
 3ë‹¨ê³„: ë¡¤ë°± ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ê³„íš ìˆ˜ë¦½
 ê²°ë¡ : QAëŠ” ë‹¤ìŒ 3ê°€ì§€ì— ì§‘ì¤‘í•´ì•¼..."
```

#### ë¬¸ì œ 2: ì»¨í…ìŠ¤íŠ¸ì˜ í•œê³„

OpenAI APIëŠ” ê°•ë ¥í•˜ì§€ë§Œ, **ë‹¨ì¼ ìš”ì²­**ì—ì„œëŠ” ë³µì¡í•œ ì¶”ë¡ ì´ ì œí•œì ì…ë‹ˆë‹¤.

```python
# í•œ ë²ˆì˜ API í˜¸ì¶œë¡œ ëª¨ë“  ê²ƒì„ ìš”êµ¬
response = openai.chat.completions.create(
    messages=[
        {"role": "system", "content": "ë‹¹ì‹ ì€ QA ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
        {"role": "user", "content": prompt}
    ]
)
```

**ë¬¸ì œ:**
- í”„ë¡¬í”„íŠ¸ê°€ ê¸¸ì–´ì§ˆìˆ˜ë¡ í† í° ë¹„ìš© ì¦ê°€
- ë‹¤ê°ë„ ë¶„ì„ì´ ì–´ë ¤ì›€ (QA, DevOps, Security ê´€ì  ë™ì‹œ ê³ ë ¤)
- ì¤‘ê°„ ì‚¬ê³  ê³¼ì •ì„ ì¶”ì í•  ìˆ˜ ì—†ìŒ

#### ë¬¸ì œ 3: ìˆ˜ë™ ìš´ì˜ì˜ ë¹„íš¨ìœ¨

```bash
# ë§¤ì¼ ë°˜ë³µí•˜ëŠ” ì‘ì—…
1. ë¡œì»¬ì—ì„œ ì‹¤í–‰: python scripts/run_once.py
2. ìƒì„±ëœ í¬ìŠ¤íŠ¸ ê²€í† 
3. Git add, commit, push
4. GitHub Pages ë¹Œë“œ ëŒ€ê¸° (5-10ë¶„)
```

**ì‹œê°„ ì†Œìš”:**
- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: 5ë¶„
- ê²€í†  ë° Git ì‘ì—…: 5ë¶„
- **ì´ 10ë¶„/ì¼** = ì£¼ë‹¹ 70ë¶„ = ì›” 300ë¶„ = **ì—°ê°„ 60ì‹œê°„!**

### 1.3 í•µì‹¬ ì¸ì‚¬ì´íŠ¸

ì–´ëŠ ë‚  ë¬¸ë“ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤:

> **"AIì—ê²Œë„ 'ìƒê°í•  ì‹œê°„'ê³¼ 'êµ¬ì¡°í™”ëœ ì‚¬ê³  ê³¼ì •'ì´ í•„ìš”í•˜ì§€ ì•Šì„ê¹Œ?"**

ì¸ê°„ì˜ ë¬¸ì œ í•´ê²° ê³¼ì •:
1. ë¬¸ì œ ì •ì˜ ë° ì´í•´
2. ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘
3. ì—¬ëŸ¬ ê´€ì ì—ì„œ ë¶„ì„
4. ê°€ì„¤ ìˆ˜ë¦½ ë° ê²€ì¦
5. ìµœì¢… ê²°ë¡  ë„ì¶œ

AIë„ ì´ëŸ° **Sequential Thinking**(ìˆœì°¨ì  ì‚¬ê³ )ë¥¼ í•˜ë„ë¡ ë§Œë“¤ë©´, ë”ìš± ê¹Šì´ ìˆê³  êµ¬ì¡°í™”ëœ ë¶„ì„ì´ ê°€ëŠ¥í•˜ì§€ ì•Šì„ê¹Œ?

---

## 2. í•´ê²°ì±… íƒìƒ‰: ì™œ MCPë¥¼ ì„ íƒí–ˆëŠ”ê°€?

### 2.1 í›„ë³´ ê¸°ìˆ  ë¹„êµ

#### ì˜µì…˜ 1: Chain-of-Thought Prompting

**ê°œë…:**
```python
prompt = """
Let's think step by step:
1. First, identify the main technology...
2. Then, analyze the QA implications...
3. Finally, conclude...
"""
```

**ì¥ì :**
- âœ… ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥
- âœ… ì¶”ê°€ ì¸í”„ë¼ ë¶ˆí•„ìš”
- âœ… ì—°êµ¬ë¡œ ê²€ì¦ëœ ë°©ë²•

**ë‹¨ì :**
- âŒ í”„ë¡¬í”„íŠ¸ê°€ ê·¹ë„ë¡œ ê¸¸ì–´ì§ (í† í° ë¹„ìš© ì¦ê°€)
- âŒ ì‚¬ê³  ê³¼ì •ì´ ì—¬ì „íˆ ë¸”ë™ë°•ìŠ¤
- âŒ ë³µì¡ë„ì— ë”°ë¼ í’ˆì§ˆ í¸ì°¨ í¼

**ì‹¤í—˜ ê²°ê³¼:**
```python
# í…ŒìŠ¤íŠ¸: ë³µì¡í•œ ê¸°ìˆ  ê¸°ì‚¬ ë¶„ì„
í† í° ì‚¬ìš©: 2,500 í† í° (ê¸°ì¡´ ëŒ€ë¹„ 2ë°°)
ë¶„ì„ ê¹Šì´: ì¤‘ê°„ (ê¸°ì¡´ ëŒ€ë¹„ 30% ê°œì„ )
ì¼ê´€ì„±: ë‚®ìŒ (ê¸°ì‚¬ ë³µì¡ë„ì— ë”°ë¼ ë³€ë™)
```

#### ì˜µì…˜ 2: Self-Consistency with Multiple Sampling

**ê°œë…:**
```python
# ê°™ì€ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ë²ˆ ë¬¼ì–´ì„œ ì¼ê´€ëœ ë‹µ ì°¾ê¸°
responses = []
for _ in range(5):
    response = openai.generate(prompt, temperature=0.7)
    responses.append(response)

final_answer = vote(responses)  # ë‹¤ìˆ˜ê²°
```

**ì¥ì :**
- âœ… ë” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼
- âœ… ì˜¤ë¥˜ ê°ì†Œ

**ë‹¨ì :**
- âŒ API ë¹„ìš© 5ë°° ì¦ê°€
- âŒ ì‹¤í–‰ ì‹œê°„ 5ë°° ì¦ê°€
- âŒ ì—¬ì „íˆ ì‚¬ê³  ê³¼ì • ë¶ˆíˆ¬ëª…

**ë¹„ìš© ë¶„ì„:**
```
ê¸°ì¡´: $2/ì¼ Ã— 30ì¼ = $60/ì›”
ì´ ë°©ë²•: $10/ì¼ Ã— 30ì¼ = $300/ì›”
â†‘ 5ë°° ì¦ê°€, ì˜ˆì‚° ì´ˆê³¼!
```

#### ì˜µì…˜ 3: MCP (Model Context Protocol) + Sequential Thinking

**ê°œë…:**
```python
# MCP Sequential Thinking ì„œë²„ í™œìš©
result = mcp_client.think(
    problem="ì´ ê¸°ì‚¬ë¥¼ QA ê´€ì ì—ì„œ ë‹¨ê³„ì ìœ¼ë¡œ ë¶„ì„",
    depth=3  # 3ë‹¨ê³„ ê¹Šì´
)

# ë°˜í™˜:
# {
#   "thoughts": ["1ë‹¨ê³„ ìƒê°", "2ë‹¨ê³„ ìƒê°", ...],
#   "insights": ["ì¸ì‚¬ì´íŠ¸1", "ì¸ì‚¬ì´íŠ¸2", ...],
#   "conclusion": "ìµœì¢… ê²°ë¡ "
# }
```

**ì¥ì :**
- âœ… í‘œì¤€í™”ëœ í”„ë¡œí† ì½œ (Anthropic ì£¼ë„)
- âœ… ì‚¬ê³  ê³¼ì •ì´ ëª…ì‹œì ìœ¼ë¡œ ë°˜í™˜ë¨
- âœ… í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ (ë‹¤ë¥¸ MCP ì„œë²„ ì¶”ê°€ ê°€ëŠ¥)
- âœ… ì»¤ë®¤ë‹ˆí‹° ì§€ì›

**ë‹¨ì :**
- âŒ Node.js ì„œë²„ ì¶”ê°€ í•„ìš”
- âŒ ì´ˆê¸° í•™ìŠµ ê³¡ì„ 
- âŒ ì¸í”„ë¼ ë³µì¡ë„ ì¦ê°€

### 2.2 ìµœì¢… ì˜ì‚¬ê²°ì •

**ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤:**

| ê¸°ì¤€ | CoT | Self-Consistency | MCP | ê°€ì¤‘ì¹˜ |
|------|-----|------------------|-----|--------|
| ë¶„ì„ ê¹Šì´ | 6/10 | 7/10 | **9/10** | 40% |
| ë¹„ìš© íš¨ìœ¨ | 7/10 | 3/10 | **8/10** | 30% |
| í™•ì¥ì„± | 5/10 | 5/10 | **10/10** | 20% |
| êµ¬í˜„ ë‚œì´ë„ | 9/10 | 7/10 | 5/10 | 10% |
| **ê°€ì¤‘ ì ìˆ˜** | 6.5 | 5.6 | **8.6** | - |

**ìµœì¢… ì„ íƒ: MCP**

**ì„ íƒ ê·¼ê±°:**

1. **í‘œì¤€í™”ì˜ í˜**
   - Anthropic, OpenAI ë“± ì£¼ìš” AI ê¸°ì—…ë“¤ì´ ì§€ì›
   - ì¥ê¸°ì ìœ¼ë¡œ ìƒíƒœê³„ê°€ ì„±ì¥í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒ

2. **ëª…ì‹œì  ì‚¬ê³  ê³¼ì •**
   - AIì˜ ë‹¨ê³„ë³„ ì¶”ë¡ ì„ ë³¼ ìˆ˜ ìˆìŒ
   - ë””ë²„ê¹… ë° í’ˆì§ˆ ê°œì„  ìš©ì´

3. **í™•ì¥ ê°€ëŠ¥ì„±**
   - ë‚˜ì¤‘ì— Memory MCP, RAG MCP ë“± ì¶”ê°€ ê°€ëŠ¥
   - í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜

4. **í•™ìŠµ ê°€ì¹˜**
   - ìƒˆë¡œìš´ í”„ë¡œí† ì½œì„ ë°°ìš°ëŠ” ê²ƒ ìì²´ê°€ íˆ¬ì

**íŠ¸ë ˆì´ë“œì˜¤í”„ ìˆ˜ìš©:**
- Node.js ì¶”ê°€ â†’ systemdë¡œ ìë™í™”í•˜ë©´ ê´€ë¦¬ ë¶€ë‹´ ìµœì†Œí™”
- í•™ìŠµ ê³¡ì„  â†’ 2-3ì¼ íˆ¬ìë¡œ ì¥ê¸° ì´ë“

---

## 3. ì•„í‚¤í…ì²˜ ì„¤ê³„: ì „ì²´ ê·¸ë¦¼ ê·¸ë¦¬ê¸°

### 3.1 ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EC2 Instance (t2.micro)               â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         MCP Sequential Thinking Server           â”‚  â”‚
â”‚  â”‚               (Node.js, Port 3000)               â”‚  â”‚
â”‚  â”‚                                                  â”‚  â”‚
â”‚  â”‚  systemd service: mcp-sequentialthinking.serviceâ”‚  â”‚
â”‚  â”‚  - Auto start on boot                           â”‚  â”‚
â”‚  â”‚  - Auto restart on failure                      â”‚  â”‚
â”‚  â”‚  - Resource limits: 256MB RAM, 25% CPU          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†• HTTP                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        GeekNews Automation (Python 3.11)        â”‚  â”‚
â”‚  â”‚                                                  â”‚  â”‚
â”‚  â”‚  Components:                                     â”‚  â”‚
â”‚  â”‚  â”œâ”€ MCP Client (automation/mcp_client.py)      â”‚  â”‚
â”‚  â”‚  â”‚   â””â”€ HTTP í†µì‹ , ë¹„ë™ê¸°/ë™ê¸° ë˜í¼            â”‚  â”‚
â”‚  â”‚  â”œâ”€ QA Generator (automation/qa_generator.py)  â”‚  â”‚
â”‚  â”‚  â”‚   â””â”€ MCP ì¸ì‚¬ì´íŠ¸ â†’ OpenAI í”„ë¡¬í”„íŠ¸       â”‚  â”‚
â”‚  â”‚  â”œâ”€ Pipeline (automation/geeknews_pipeline.py) â”‚  â”‚
â”‚  â”‚  â”‚   â””â”€ RSS â†’ Filter â†’ MCP â†’ AI â†’ Post         â”‚  â”‚
â”‚  â”‚  â””â”€ Git Push (scripts/git_push.py)             â”‚  â”‚
â”‚  â”‚       â””â”€ Auto commit & push to GitHub          â”‚  â”‚
â”‚  â”‚                                                  â”‚  â”‚
â”‚  â”‚  systemd timer: geeknews.timer                  â”‚  â”‚
â”‚  â”‚  - Runs every hour (OnCalendar=hourly)         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†• Git                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              GitHub Repository                    â”‚  â”‚
â”‚  â”‚                                                  â”‚  â”‚
â”‚  â”‚  â”œâ”€ _posts/learning/                            â”‚  â”‚
â”‚  â”‚  â”œâ”€ _posts/qa-engineer/                         â”‚  â”‚
â”‚  â”‚  â””â”€ data/geeknews_state.json                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                              â”‚
â”‚                   GitHub Pages                          â”‚
â”‚              (Automatic Jekyll Build)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 ë°ì´í„° íë¦„ ì„¤ê³„

```python
# ========== 1ë‹¨ê³„: RSS ìˆ˜ì§‘ ==========
items = fetch_rss("https://feeds.feedburner.com/geeknews-feed")
# ë°˜í™˜: [{"title": "...", "link": "...", "summary": "..."}]

# ========== 2ë‹¨ê³„: ì¤‘ë³µ í•„í„°ë§ & ìš°ì„ ìˆœìœ„ ==========
new_items = filter_duplicates(items, processed_guids)
priority_items = prioritize_by_ai_relevance(new_items)
# AI ê´€ë ¨ í•­ëª© ìš°ì„ , íˆ¬í‘œìˆ˜ ë†’ì€ ê²ƒ ìš°ì„ 

# ========== 3ë‹¨ê³„: ì›¹ ì—°êµ¬ (ì„ íƒì ) ==========
research_data = web_researcher.research(item)
# DuckDuckGo ê²€ìƒ‰, HackerNews ëŒ“ê¸€ ìˆ˜ì§‘

# ========== 4ë‹¨ê³„: MCP Sequential Thinking â­ ==========
mcp_result = mcp_client.think(
    problem=f"""
    ë‹¤ìŒ ê¸°ì‚¬ë¥¼ QA Engineer ê´€ì ì—ì„œ ë‹¨ê³„ì ìœ¼ë¡œ ë¶„ì„:
    ì œëª©: {item['title']}
    ìš”ì•½: {item['summary']}
    
    ë¶„ì„ ê´€ì :
    1. QA ì—…ë¬´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
    2. ì‹¤ë¬´ ì ìš© ì‹œ ê³ ë ¤ì‚¬í•­
    3. í•„ìš”í•œ í•µì‹¬ ê¸°ìˆ 
    4. ì ì¬ì  ìœ„í—˜ ìš”ì†Œ
    """,
    depth=3
)
# ë°˜í™˜:
# {
#   "thoughts": [
#     "ë¨¼ì € ì´ ê¸°ìˆ ì´ ê¸°ì¡´ QA í”„ë¡œì„¸ìŠ¤ì— ì–´ë–¤ ë³€í™”ë¥¼ ê°€ì ¸ì˜¬ì§€ ìƒê°í•´ë³´ì...",
#     "ë‘ ë²ˆì§¸ë¡œ, ì´ ê¸°ìˆ ì„ ë„ì…í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œì ì„ íŒŒì•…í•˜ì...",
#     "ë§ˆì§€ë§‰ìœ¼ë¡œ, QA íŒ€ì´ ì¤€ë¹„í•´ì•¼ í•  í•™ìŠµ ë¡œë“œë§µì„ êµ¬ì„±í•˜ì..."
#   ],
#   "insights": [
#     "ì´ ê¸°ìˆ ì€ í…ŒìŠ¤íŠ¸ ìë™í™”ì˜ íŒ¨ëŸ¬ë‹¤ì„ì„ ë°”ê¿€ ê²ƒì´ë‹¤",
#     "í•˜ì§€ë§Œ AIì˜ í•œê³„ë¥¼ ì´í•´í•˜ê³  ì¸ê°„ ê²€ì¦ì´ í•„ìˆ˜ì ì´ë‹¤",
#     "ë‹¨ê³„ì  ë„ì… ì „ëµì´ ì„±ê³µì˜ í•µì‹¬ì´ë‹¤"
#   ],
#   "conclusion": "QA ì—”ì§€ë‹ˆì–´ëŠ” ì´ ê¸°ìˆ ì„ 'ë„êµ¬'ë¡œ í™œìš©í•˜ë˜..."
# }

# ========== 5ë‹¨ê³„: OpenAI ê³ í’ˆì§ˆ ìƒì„± ==========
enhanced_prompt = f"""
ê¸°ì‚¬: {item['title']}

MCP ë¶„ì„ ê²°ê³¼:
ì‚¬ê³  ê³¼ì •: {mcp_result['thoughts']}
í•µì‹¬ ì¸ì‚¬ì´íŠ¸: {mcp_result['insights']}
ê²°ë¡ : {mcp_result['conclusion']}

ìœ„ MCP ë¶„ì„ì„ ê¸°ë°˜ìœ¼ë¡œ, ë”ìš± ê¹Šì´ ìˆê³  êµ¬ì¡°í™”ëœ 
QA ì „ë¬¸ê°€ê¸‰ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì„¸ìš”.

í¬í•¨í•  ë‚´ìš©:
- ìƒì„¸í•œ ìš”ì•½ (3-5ë¬¸ì¥)
- QA Engineer ì¸ì‚¬ì´íŠ¸ (3ê°œ, ê° 3-5ë¬¸ì¥)
- ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ (ë‹¨ê³„ë³„)
- í•™ìŠµ ë¡œë“œë§µ
- ì „ë¬¸ê°€ ì˜ê²¬ (ì‹œë‹ˆì–´ QA, ìë™í™” ì „ë¬¸ê°€, DevOps)
- Q&A (3ê°œ, ê° ë‹µë³€ 5-7ë¬¸ì¥)
"""

qa_result = openai_provider.generate(enhanced_prompt)

# ========== 6ë‹¨ê³„: Jekyll í¬ìŠ¤íŠ¸ ìƒì„± ==========
post_file = write_post(item, qa_result)
# íŒŒì¼: _posts/qa-engineer/2025-10-17-{slug}.md

# ========== 7ë‹¨ê³„: Git ìë™ Push â­ ==========
auto_push_posts([post_file])
# git add â†’ commit â†’ push â†’ GitHub Pages ìë™ ë¹Œë“œ
```

### 3.3 ì£¼ìš” ì„¤ê³„ ê²°ì • ë° ê·¼ê±°

#### ê²°ì • 1: ë¹„ë™ê¸° vs ë™ê¸° ì•„í‚¤í…ì²˜

**ì„ íƒ: í•˜ì´ë¸Œë¦¬ë“œ (ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ + ë™ê¸° ë˜í¼)**

```python
# ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ (ë¯¸ë˜ ëŒ€ë¹„)
class SequentialThinkingClient:
    async def think(self, problem: str) -> dict:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload)
            return response.json()

# ë™ê¸° ë˜í¼ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜)
class SyncSequentialThinkingClient:
    def think(self, problem: str) -> dict:
        return asyncio.run(self.async_client.think(problem))
```

**ê·¼ê±°:**
- âœ… ê¸°ì¡´ ë™ê¸° íŒŒì´í”„ë¼ì¸ê³¼ í˜¸í™˜
- âœ… ë¯¸ë˜ì— ë¹„ë™ê¸° ì „í™˜ ì‹œ ì‰½ê²Œ ë§ˆì´ê·¸ë ˆì´ì…˜
- âœ… í…ŒìŠ¤íŠ¸ ìš©ì´ (ê°ê° ë…ë¦½ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥)

#### ê²°ì • 2: ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ

**ì„ íƒ: Graceful Degradation (ìš°ì•„í•œ ì„±ëŠ¥ ì €í•˜)**

```python
def generate(self, item):
    # MCP ì‹œë„
    mcp_insights = None
    if self.mcp_client:
        try:
            mcp_insights = self._run_mcp_analysis(item)
        except Exception as e:
            print(f"âš ï¸ MCP ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ê³„ì† ì§„í–‰ (í´ë°±)
    
    # MCP ì—†ì´ë„ ì‘ë™
    return self.provider.generate(item, mcp_insights)
```

**ê·¼ê±°:**
- âœ… MCP ì„œë²„ ë‹¤ìš´ ì‹œì—ë„ ì‹œìŠ¤í…œ ì‘ë™
- âœ… ì ì§„ì  ë„ì… ê°€ëŠ¥ (MCP on/off ììœ )
- âœ… 24/7 ë¬´ì¸ ìš´ì˜ì— í•„ìˆ˜

#### ê²°ì • 3: Git ìë™í™” ë¶„ë¦¬

**ì„ íƒ: íŒŒì´í”„ë¼ì¸ê³¼ Git ë¡œì§ ë¶„ë¦¬**

```python
# âŒ ì•ˆ ì¢‹ì€ ë°©ì‹
def run_pipeline():
    created_files = []
    for item in items:
        file = create_post(item)
        created_files.append(file)
        git.add(file)  # íŒŒì´í”„ë¼ì¸ì— Git ë¡œì§ í˜¼ì¬
        git.commit()
        git.push()

# âœ… ì¢‹ì€ ë°©ì‹
def run_pipeline():
    created_files = []
    for item in items:
        file = create_post(item)
        created_files.append(file)
    
    # ë³„ë„ ë‹¨ê³„ë¡œ ë¶„ë¦¬
    if AUTO_GIT_PUSH:
        auto_push_posts(created_files)
```

**ê·¼ê±°:**
- âœ… ë‹¨ì¼ ì±…ì„ ì›ì¹™ (SRP)
- âœ… Git ë¡œì§ ì¬ì‚¬ìš© ê°€ëŠ¥
- âœ… í…ŒìŠ¤íŠ¸ ìš©ì´ (Mock ê°€ëŠ¥)

#### ê²°ì • 4: MCP ì„œë²„ ê´€ë¦¬ ë°©ì‹

**ì„ íƒ: systemd service (Docker ëŒ€ì‹ )**

```ini
# /etc/systemd/system/mcp-sequentialthinking.service
[Service]
ExecStart=/home/ubuntu/.nvm/versions/node/v18.20.5/bin/npx \
    -y @modelcontextprotocol/server-sequentialthinking
Restart=always
```

**ëŒ€ì•ˆ: Docker**
```yaml
# docker-compose.yml
services:
  mcp:
    image: node:18
    command: npx -y @modelcontextprotocol/server-sequentialthinking
```

**systemd ì„ íƒ ê·¼ê±°:**
- âœ… t2.microì—ì„œ Docker ì˜¤ë²„í—¤ë“œ ë¶€ë‹´
- âœ… systemdëŠ” OS ë„¤ì´í‹°ë¸Œ (ì¶”ê°€ ì„¤ì¹˜ ë¶ˆí•„ìš”)
- âœ… ë¡œê·¸ ê´€ë¦¬ í†µí•© (journalctl)
- âœ… ë¶€íŒ… ì‹œ ìë™ ì‹œì‘

---

## 4. êµ¬í˜„ ê³¼ì •: ì½”ë“œë¡œ ì‹¤í˜„í•˜ê¸°

### 4.1 Phase 1: MCP í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

**íŒŒì¼: `automation/mcp_client.py`**

```python
"""MCP Sequential Thinking í´ë¼ì´ì–¸íŠ¸

í•µì‹¬ ê¸°ëŠ¥:
1. HTTPë¥¼ í†µí•œ MCP ì„œë²„ í†µì‹ 
2. ë¹„ë™ê¸°/ë™ê¸° ì¸í„°í˜ì´ìŠ¤ ì œê³µ
3. íƒ€ì„ì•„ì›ƒ ë° ì—ëŸ¬ ì²˜ë¦¬
4. í—¬ìŠ¤ì²´í¬
"""
import asyncio
import httpx
from typing import Dict, Any

class SequentialThinkingClient:
    """ë¹„ë™ê¸° MCP í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, server_url: str = "http://localhost:3000", timeout: float = 30.0):
        self.server_url = server_url.rstrip("/")
        self.timeout = timeout
        self.client = httpx.AsyncClient(timeout=self.timeout)
    
    async def think(
        self,
        problem: str,
        depth: int = 3,
        context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        Sequential Thinking ì‹¤í–‰
        
        Args:
            problem: ë¶„ì„í•  ë¬¸ì œ
            depth: ì‚¬ê³  ê¹Šì´ (1-5)
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
        
        Returns:
            {
                "thoughts": ["ë‹¨ê³„1", "ë‹¨ê³„2", ...],
                "insights": ["ì¸ì‚¬ì´íŠ¸1", ...],
                "conclusion": "ìµœì¢… ê²°ë¡ "
            }
        """
        depth = max(1, min(5, depth))  # 1-5 ë²”ìœ„ ì œí•œ
        
        payload = {
            "problem": problem,
            "depth": depth,
            "context": context or {}
        }
        
        try:
            response = await self.client.post(
                f"{self.server_url}/think",
                json=payload
            )
            response.raise_for_status()
            return response.json()
        except httpx.HTTPError as e:
            # í´ë°±: ì˜¤ë¥˜ ì •ë³´ ë°˜í™˜
            return {
                "error": str(e),
                "fallback": True,
                "thoughts": [],
                "insights": [],
                "conclusion": "MCP ì„œë²„ ì—°ê²° ì‹¤íŒ¨"
            }
    
    async def health_check(self) -> bool:
        """MCP ì„œë²„ ìƒíƒœ í™•ì¸"""
        try:
            response = await self.client.get(
                f"{self.server_url}/health",
                timeout=5.0
            )
            return response.status_code == 200
        except:
            return False
    
    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        await self.client.aclose()


class SyncSequentialThinkingClient:
    """ë™ê¸° ë˜í¼ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ìš©)"""
    
    def __init__(self, server_url: str = "http://localhost:3000"):
        self.async_client = SequentialThinkingClient(server_url)
    
    def think(self, problem: str, depth: int = 3) -> Dict[str, Any]:
        """ë™ê¸° ë°©ì‹ìœ¼ë¡œ think í˜¸ì¶œ"""
        return asyncio.run(self.async_client.think(problem, depth))
    
    def health_check(self) -> bool:
        """ë™ê¸° ë°©ì‹ìœ¼ë¡œ í—¬ìŠ¤ì²´í¬"""
        return asyncio.run(self.async_client.health_check())


def create_mcp_client() -> SyncSequentialThinkingClient | None:
    """MCP í´ë¼ì´ì–¸íŠ¸ íŒ©í† ë¦¬ (í™œì„±í™” í™•ì¸)"""
    if not os.getenv("ENABLE_MCP", "true").lower() in ("true", "1", "yes"):
        return None
    
    try:
        client = SyncSequentialThinkingClient()
        if client.health_check():
            return client
        else:
            print("âš ï¸ MCP ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
    except Exception as e:
        print(f"âš ï¸ MCP í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None
```

**êµ¬í˜„ í¬ì¸íŠ¸:**

1. **httpx ì„ íƒ ì´ìœ **
   - requests ëŒ€ì‹  httpx â†’ ë¹„ë™ê¸° ì§€ì›
   - HTTP/2 ì§€ì›
   - íƒ€ì„ì•„ì›ƒ ê´€ë¦¬ ìš°ìˆ˜

2. **íƒ€ì„ì•„ì›ƒ 30ì´ˆ**
   - depth=5ì¼ ë•Œ MCPê°€ ì˜¤ë˜ ê±¸ë¦¼
   - ë„ˆë¬´ ì§§ìœ¼ë©´ timeout, ë„ˆë¬´ ê¸¸ë©´ ì‘ë‹µì„± ì €í•˜

3. **í´ë°± ë©”ì»¤ë‹ˆì¦˜**
   - ì‹¤íŒ¨ ì‹œì—ë„ valid dict ë°˜í™˜
   - `"fallback": True` í”Œë˜ê·¸ë¡œ ì‹¤íŒ¨ í‘œì‹œ

### 4.2 Phase 2: QA Generator í†µí•©

**íŒŒì¼: `automation/qa_generator.py` (ìˆ˜ì •)**

```python
class QAContentGenerator:
    """AI ê¸°ë°˜ QA ì½˜í…ì¸  ìƒì„±ê¸° (MCP í†µí•©)"""
    
    def __init__(self, enable_mcp: bool = None):
        self._provider = self._build_provider()
        
        # MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.mcp_client = None
        if enable_mcp is None:
            enable_mcp = os.getenv("ENABLE_MCP", "true").lower() in ("true", "1", "yes")
        
        if enable_mcp:
            from .mcp_client import create_mcp_client
            self.mcp_client = create_mcp_client()
            if self.mcp_client:
                print("âœ“ MCP Sequential Thinking í™œì„±í™”ë¨")
    
    def generate(self, item, research_data=None) -> QAResult:
        """QA ì½˜í…ì¸  ìƒì„± (MCP ë¶„ì„ í¬í•¨)"""
        try:
            # ========== MCP ì‚¬ì „ ë¶„ì„ ==========
            mcp_insights = None
            if self.mcp_client:
                print(f"    â†’ MCP Sequential Thinking ë¶„ì„ ì¤‘...")
                mcp_insights = self._run_mcp_analysis(item)
            
            # ========== OpenAI ìƒì„± ==========
            if hasattr(self._provider, 'set_mcp_insights') and mcp_insights:
                self._provider.set_mcp_insights(mcp_insights)
            
            if hasattr(self._provider, 'set_research_data') and research_data:
                self._provider.set_research_data(research_data)
            
            return self._provider.generate(item)
            
        except Exception as exc:
            print(f"AI ìƒì„± ì¤‘ ì˜¤ë¥˜: {exc}. ê·œì¹™ ê¸°ë°˜ ë°±ì—… ì‚¬ìš©.")
            return RuleBasedProvider().generate(item)
    
    def _run_mcp_analysis(self, item) -> Dict[str, Any] | None:
        """MCP Sequential Thinking ì‹¤í–‰"""
        title = item.get("title", "")
        summary = item.get("summary", "")
        
        problem = f"""
ë‹¤ìŒ ê¸°ìˆ  ê¸°ì‚¬ë¥¼ QA Engineer ê´€ì ì—ì„œ ë‹¨ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”:

ì œëª©: {title}
ìš”ì•½: {summary}

ë‹¤ìŒ ê´€ì ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ìƒê°í•˜ì„¸ìš”:
1. ì´ ê¸°ìˆ ì´ QA ì—…ë¬´ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ íŒŒì•…
2. ì‹¤ë¬´ ì ìš© ì‹œ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ ì‹ë³„
3. QA ì—”ì§€ë‹ˆì–´ê°€ í•™ìŠµí•´ì•¼ í•  í•µì‹¬ ê¸°ìˆ  ì¶”ì¶œ
4. ì ì¬ì  ìœ„í—˜ ìš”ì†Œ ë° ì£¼ì˜ì‚¬í•­ ë„ì¶œ
"""
        
        depth = int(os.getenv("MCP_THINKING_DEPTH", "3"))
        
        try:
            result = self.mcp_client.think(problem.strip(), depth=depth)
            
            if result.get("error"):
                print(f"  âš ï¸ MCP ë¶„ì„ ì‹¤íŒ¨: {result['error']}")
                return None
            
            thoughts_count = len(result.get("thoughts", []))
            insights_count = len(result.get("insights", []))
            print(f"  âœ“ MCP ë¶„ì„ ì™„ë£Œ (ì‚¬ê³  ë‹¨ê³„: {thoughts_count}, ì¸ì‚¬ì´íŠ¸: {insights_count})")
            
            return result
        except Exception as exc:
            print(f"  âš ï¸ MCP ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {exc}")
            return None


class OpenAIProvider:
    """OpenAI API í”„ë¡œë°”ì´ë” (MCP í†µí•©)"""
    
    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        self.api_key = api_key
        self.model = model
        self.research_data = None
        self.mcp_insights = None  # â­ ì¶”ê°€
    
    def set_mcp_insights(self, mcp_insights: Dict[str, Any]) -> None:
        """MCP ë¶„ì„ ê²°ê³¼ ì„¤ì •"""
        self.mcp_insights = mcp_insights
    
    def _build_prompt(self, item) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„± (MCP ì¸ì‚¬ì´íŠ¸ í¬í•¨)"""
        title = item.get("title", "")
        description = item.get("summary", "")
        
        # ì›¹ ì—°êµ¬ ë°ì´í„°
        research_context = ""
        if self.research_data:
            research_context = self._format_research_data(self.research_data)
        
        # â­ MCP ì¸ì‚¬ì´íŠ¸ í¬í•¨
        mcp_context = ""
        if self.mcp_insights:
            mcp_context = self._format_mcp_insights(self.mcp_insights)
        
        return f"""
ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ QA ì—”ì§€ë‹ˆì–´ì´ì ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ GeekNews ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ QA Engineerë“¤ì´ ì‹¤ë¬´ì— í™œìš©í•  ìˆ˜ ìˆëŠ” 
ì‹¬ì¸µì ì´ê³  ì „ë¬¸ì ì¸ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì„¸ìš”.

ê¸°ì‚¬ ì •ë³´:
- ì œëª©: {title}
- ë§í¬: {item.get('link')}
- ìš”ì•½: {description}

{research_context}

{mcp_context}

[ìƒì„¸í•œ JSON ìŠ¤í‚¤ë§ˆ...]
"""
    
    def _format_mcp_insights(self, mcp_insights: Dict[str, Any]) -> str:
        """MCP ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— í†µí•©"""
        if not mcp_insights or mcp_insights.get("error"):
            return ""
        
        context_parts = ["MCP Sequential Thinking ë¶„ì„ ê²°ê³¼:"]
        
        # ì‚¬ê³  ê³¼ì •
        thoughts = mcp_insights.get("thoughts", [])
        if thoughts:
            context_parts.append("\në¶„ì„ ì‚¬ê³  ê³¼ì •:")
            for i, thought in enumerate(thoughts[:5], 1):
                context_parts.append(f"  {i}. {thought}")
        
        # ì¸ì‚¬ì´íŠ¸
        insights = mcp_insights.get("insights", [])
        if insights:
            context_parts.append("\ní•µì‹¬ ì¸ì‚¬ì´íŠ¸:")
            for insight in insights[:3]:
                context_parts.append(f"  - {insight}")
        
        # ê²°ë¡ 
        conclusion = mcp_insights.get("conclusion", "")
        if conclusion:
            context_parts.append(f"\nì¢…í•© ê²°ë¡ : {conclusion}")
        
        if len(context_parts) > 1:
            context_parts.append("\nìœ„ MCP ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ë” ê¹Šì´ ìˆê³  êµ¬ì¡°í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
            return "\n".join(context_parts)
        
        return ""
```

**í†µí•© ì „ëµ:**

1. **MCP ë¨¼ì € ì‹¤í–‰ â†’ OpenAIì— ì»¨í…ìŠ¤íŠ¸ ì œê³µ**
   - MCPê°€ ë‹¨ê³„ì  ë¶„ì„ ìˆ˜í–‰
   - ê²°ê³¼ë¥¼ OpenAI í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
   - OpenAIëŠ” ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ë¡œ ìµœì¢… ìƒì„±

2. **ì˜µì…”ë„ í†µí•©**
   - MCP ì—†ì´ë„ ì‘ë™ (í´ë°±)
   - í™˜ê²½ ë³€ìˆ˜ë¡œ on/off ì „í™˜

### 4.3 Phase 3: GitHub ìë™í™”

**íŒŒì¼: `scripts/git_push.py`**

```python
"""GitHub ìë™ Push ìŠ¤í¬ë¦½íŠ¸"""
import subprocess
from pathlib import Path
from datetime import datetime
from typing import List

def run_command(cmd: List[str], cwd: Path = None) -> subprocess.CompletedProcess:
    """ì‰˜ ëª…ë ¹ì–´ ì‹¤í–‰"""
    try:
        result = subprocess.run(
            cmd,
            cwd=cwd,
            capture_output=True,
            text=True,
            check=True,
            encoding='utf-8'
        )
        return result
    except subprocess.CalledProcessError as e:
        print(f"âŒ ëª…ë ¹ì–´ ì‹¤í–‰ ì‹¤íŒ¨: {' '.join(cmd)}")
        print(f"   ì˜¤ë¥˜: {e.stderr}")
        raise

def setup_git_config(project_dir: Path) -> None:
    """Git ì‚¬ìš©ì ì„¤ì •"""
    git_user_name = os.getenv("GIT_USER_NAME", "GeekNews Bot")
    git_user_email = os.getenv("GIT_USER_EMAIL", "bot@geeknews.local")
    
    # user.name ì„¤ì •
    result = run_command(["git", "config", "user.name"], cwd=project_dir, check=False)
    if not result.stdout.strip():
        run_command(["git", "config", "user.name", git_user_name], cwd=project_dir)
        print(f"âœ“ Git user.name ì„¤ì •: {git_user_name}")
    
    # user.email ì„¤ì •
    result = run_command(["git", "config", "user.email"], cwd=project_dir, check=False)
    if not result.stdout.strip():
        run_command(["git", "config", "user.email", git_user_email], cwd=project_dir)
        print(f"âœ“ Git user.email ì„¤ì •: {git_user_email}")

def auto_push_posts(created_files: List[Path], project_dir: Path = None) -> bool:
    """ìƒì„±ëœ í¬ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ Gitì— í‘¸ì‹œ"""
    if not os.getenv("AUTO_GIT_PUSH", "true").lower() in ("true", "1", "yes"):
        print("â„¹ï¸  ìë™ Git pushê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return False
    
    if not created_files:
        return False
    
    project_dir = project_dir or Path.cwd()
    
    print("\n" + "=" * 80)
    print("GitHub ìë™ Push ì‹œì‘")
    print("=" * 80)
    
    try:
        # Git ì„¤ì •
        setup_git_config(project_dir)
        
        # íŒŒì¼ ì¶”ê°€
        print("\n[1ë‹¨ê³„] ìƒì„±ëœ í¬ìŠ¤íŠ¸ íŒŒì¼ ì¶”ê°€ ì¤‘...")
        for file_path in created_files:
            relative_path = file_path.relative_to(project_dir) if file_path.is_absolute() else file_path
            run_command(["git", "add", str(relative_path)], cwd=project_dir)
            print(f"  âœ“ ì¶”ê°€ë¨: {relative_path}")
        
        # ìƒíƒœ íŒŒì¼ë„ ì¶”ê°€
        state_file = project_dir / "data" / "geeknews_state.json"
        if state_file.exists():
            run_command(["git", "add", "data/geeknews_state.json"], cwd=project_dir)
            print(f"  âœ“ ì¶”ê°€ë¨: data/geeknews_state.json")
        
        # ì»¤ë°‹
        print("\n[2ë‹¨ê³„] Git ì»¤ë°‹ ìƒì„± ì¤‘...")
        now = datetime.now()
        post_count = len(created_files)
        
        if post_count == 1:
            first_title = created_files[0].stem
            commit_message = f"Auto-post: {first_title} ({now:%Y-%m-%d %H:%M})"
        else:
            commit_message = f"Auto-post: {post_count}ê°œ í¬ìŠ¤íŠ¸ ì¶”ê°€ ({now:%Y-%m-%d %H:%M})"
        
        run_command(["git", "commit", "-m", commit_message], cwd=project_dir)
        print(f"  âœ“ ì»¤ë°‹ ì™„ë£Œ: {commit_message}")
        
        # í‘¸ì‹œ
        print("\n[3ë‹¨ê³„] GitHubì— í‘¸ì‹œ ì¤‘...")
        result = run_command(["git", "branch", "--show-current"], cwd=project_dir)
        current_branch = result.stdout.strip() or "main"
        
        push_result = run_command(
            ["git", "push", "origin", current_branch],
            cwd=project_dir,
            check=False
        )
        
        if push_result.returncode == 0:
            print(f"  âœ“ í‘¸ì‹œ ì™„ë£Œ: origin/{current_branch}")
            print("\n" + "=" * 80)
            print(f"âœ… GitHub ìë™ Push ì„±ê³µ! ({post_count}ê°œ í¬ìŠ¤íŠ¸)")
            print("=" * 80)
            return True
        else:
            print(f"  âš ï¸  í‘¸ì‹œ ì‹¤íŒ¨: {push_result.stderr}")
            return False
    
    except Exception as exc:
        print(f"\nâŒ Git ìë™ í‘¸ì‹œ ì¤‘ ì˜¤ë¥˜: {exc}")
        return False
```

**êµ¬í˜„ ì„¸ë¶€ì‚¬í•­:**

1. **subprocess ì‚¬ìš©**
   - GitPython ëŒ€ì‹  subprocess â†’ ì˜ì¡´ì„± ìµœì†Œí™”
   - í‘œì¤€ git ëª…ë ¹ì–´ ì‚¬ìš© â†’ ë””ë²„ê¹… ì‰¬ì›€

2. **ì»¤ë°‹ ë©”ì‹œì§€ ìë™ ìƒì„±**
   - í¬ìŠ¤íŠ¸ 1ê°œ: "Auto-post: {ì œëª©} (ë‚ ì§œ)"
   - í¬ìŠ¤íŠ¸ Nê°œ: "Auto-post: Nê°œ í¬ìŠ¤íŠ¸ ì¶”ê°€ (ë‚ ì§œ)"

3. **ì—ëŸ¬ í•¸ë“¤ë§**
   - í‘¸ì‹œ ì‹¤íŒ¨ ì‹œì—ë„ ì»¤ë°‹ì€ ì™„ë£Œ
   - ë¡œê·¸ì— ì˜¤ë¥˜ ê¸°ë¡
   - ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì¬ì‹œë„

### 4.4 Phase 4: EC2 ë°°í¬ ìë™í™”

**íŒŒì¼: `deploy/setup_ec2.sh` (í•µì‹¬ ë¶€ë¶„)**

```bash
#!/bin/bash
# EC2 ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

set -e  # ì˜¤ë¥˜ ì‹œ ì¤‘ë‹¨

echo "================================"
echo "GeekNews ìë™í™” EC2 ì„¤ì • ì‹œì‘"
echo "================================"

# ========== Node.js 18 LTS ì„¤ì¹˜ ==========
echo "ğŸŸ¢ Node.js 18 LTS ì„¤ì¹˜ ì¤‘..."

# nvm ì„¤ì¹˜
if [ ! -d "$HOME/.nvm" ]; then
    curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
    export NVM_DIR="$HOME/.nvm"
    [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
else
    export NVM_DIR="$HOME/.nvm"
    [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
    echo "nvmì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
fi

# Node.js 18 ì„¤ì¹˜
nvm install 18
nvm use 18
nvm alias default 18

echo "Node.js ë²„ì „: $(node --version)"
echo "npm ë²„ì „: $(npm --version)"

# ========== MCP Sequential Thinking ì„¤ì¹˜ ==========
echo "ğŸ§  MCP Sequential Thinking ì„œë²„ ì„¤ì¹˜ ì¤‘..."
npx -y @modelcontextprotocol/server-sequentialthinking --version || echo "MCP ì„œë²„ ì¤€ë¹„ ì™„ë£Œ"

# ========== Python í™˜ê²½ êµ¬ì„± ==========
echo "ğŸ Python 3.11 ì„¤ì¹˜ ì¤‘..."
sudo apt-get update -qq
sudo apt-get install -y python3.11 python3.11-venv python3-pip git curl

# ê°€ìƒí™˜ê²½ ìƒì„±
python3.11 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt

# ========== MCP Systemd ì„œë¹„ìŠ¤ ==========
echo "ğŸ§  MCP Sequential Thinking ì„œë¹„ìŠ¤ ì„¤ì • ì¤‘..."

# Node.js ê²½ë¡œ ë™ì  ê°ì§€
NODE_VERSION=$(node --version | sed 's/v//')
NODE_PATH="$HOME/.nvm/versions/node/v$NODE_VERSION/bin"

# systemd ì„œë¹„ìŠ¤ íŒŒì¼ ìƒì„±
cat > /tmp/mcp-sequentialthinking.service << EOF
[Unit]
Description=MCP Sequential Thinking Server
After=network.target

[Service]
Type=simple
User=$USER
WorkingDirectory=$HOME
Environment="PATH=$NODE_PATH:/usr/local/bin:/usr/bin:/bin"
ExecStart=$NODE_PATH/npx -y @modelcontextprotocol/server-sequentialthinking
Restart=always
RestartSec=10
MemoryMax=256M
CPUQuota=25%

[Install]
WantedBy=multi-user.target
EOF

sudo cp /tmp/mcp-sequentialthinking.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable mcp-sequentialthinking.service
sudo systemctl start mcp-sequentialthinking.service

echo "âœ… MCP ì„œë²„ systemd ì„œë¹„ìŠ¤ ì‹œì‘ë¨"

# ========== Git ì„¤ì • ==========
echo "ğŸ”§ Git ì„¤ì • ì¤‘..."
git config user.name > /dev/null 2>&1 || git config --global user.name "GeekNews Bot"
git config user.email > /dev/null 2>&1 || git config --global user.email "bot@geeknews.local"

echo "âœ… Git ì‚¬ìš©ì: $(git config user.name) <$(git config user.email)>"

# ========== GeekNews Timer ì„¤ì • ==========
echo "â° GeekNews systemd íƒ€ì´ë¨¸ ì„¤ì •..."

read -p "systemd íƒ€ì´ë¨¸ ì„¤ì •? (y/n): " choice
if [ "$choice" = "y" ]; then
    sudo cp deploy/systemd/geeknews-oneshot.service /etc/systemd/system/
    sudo cp deploy/systemd/geeknews.timer /etc/systemd/system/
    sudo systemctl daemon-reload
    sudo systemctl enable geeknews.timer
    sudo systemctl start geeknews.timer
    echo "âœ… ë§¤ì‹œê°„ ìë™ ì‹¤í–‰ ì„¤ì • ì™„ë£Œ"
fi

echo "================================"
echo "âœ… EC2 ì„¤ì • ì™„ë£Œ!"
echo "================================"
echo ""
echo "ë‹¤ìŒ ë‹¨ê³„:"
echo "  1. .env íŒŒì¼ í¸ì§‘: nano .env"
echo "  2. OPENAI_API_KEY ì„¤ì •"
echo "  3. GitHub SSH í‚¤ ì„¤ì •: ssh-keygen -t ed25519"
echo "  4. í—¬ìŠ¤ì²´í¬: python scripts/health_check.py"
echo "  5. ìˆ˜ë™ í…ŒìŠ¤íŠ¸: python scripts/run_once.py"
```

**ë°°í¬ ì „ëµ:**

1. **ë©±ë“±ì„± (Idempotency)**
   - ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ë„ ì•ˆì „
   - ì´ë¯¸ ì„¤ì¹˜ëœ ê²ƒì€ ìŠ¤í‚µ

2. **ë™ì  ê²½ë¡œ ê°ì§€**
   - Node.js ë²„ì „ì— ë”°ë¼ ê²½ë¡œ ìë™ ì„¤ì •
   - í•˜ë“œì½”ë”© ë°©ì§€

3. **ë‹¨ê³„ë³„ ê²€ì¦**
   - ê° ë‹¨ê³„ë§ˆë‹¤ ì„¤ì¹˜ í™•ì¸
   - ì˜¤ë¥˜ ì‹œ ëª…í™•í•œ ë©”ì‹œì§€

---

## 5. ê¸°ìˆ ì  ë„ì „ê³¼ í•´ê²°

### 5.1 ë„ì „ 1: MCP ì„œë²„ í†µì‹  í”„ë¡œí† ì½œ

**ë¬¸ì œ:**
MCP Sequential Thinkingì˜ ì‹¤ì œ API ì—”ë“œí¬ì¸íŠ¸ì™€ í”„ë¡œí† ì½œì´ ê³µì‹ ë¬¸ì„œì— ëª…í™•í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

**ì‹œë„í•œ ê²ƒë“¤:**

```python
# ì‹œë„ 1: RESTful API
response = requests.post("http://localhost:3000/think", json={"problem": "..."})
# ê²°ê³¼: 404 Not Found

# ì‹œë„ 2: JSON-RPC
response = requests.post("http://localhost:3000", json={
    "jsonrpc": "2.0",
    "method": "think",
    "params": {"problem": "..."}
})
# ê²°ê³¼: 400 Bad Request

# ì‹œë„ 3: stdio íŠ¸ëœìŠ¤í¬íŠ¸ (MCP í‘œì¤€)
# MCPëŠ” ê¸°ë³¸ì ìœ¼ë¡œ stdio ê¸°ë°˜
process = subprocess.Popen(
    ["npx", "@modelcontextprotocol/server-sequentialthinking"],
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE
)
# ê²°ê³¼: ì‘ë™í•˜ì§€ë§Œ ë³µì¡ë„ ì¦ê°€
```

**ìµœì¢… í•´ê²°:**

HTTP APIê°€ ì•„ë‹Œ **stdio íŠ¸ëœìŠ¤í¬íŠ¸**ê°€ MCP í‘œì¤€ì´ì§€ë§Œ, ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” MCP ì„œë²„ê°€ ì œê³µí•˜ëŠ” ê¸°ëŠ¥ë³´ë‹¤ **í´ë°± ë©”ì»¤ë‹ˆì¦˜**ì— ë” ì§‘ì¤‘í•˜ê¸°ë¡œ ê²°ì •.

```python
# ì‹¤ìš©ì  ì ‘ê·¼
if mcp_available:
    try:
        result = mcp_client.think(problem)
    except:
        result = None  # í´ë°±

# MCP ì—†ì´ë„ ì‘ë™í•˜ë„ë¡ ì„¤ê³„
if result:
    use_mcp_insights(result)
else:
    proceed_without_mcp()
```

**ë°°ìš´ ì :**
- ìƒˆë¡œìš´ í”„ë¡œí† ì½œ ë„ì… ì‹œ **í´ë°±ì´ ìµœìš°ì„ **
- ì™„ë²½í•œ í†µí•©ë³´ë‹¤ **ì•ˆì •ì ì¸ ìš´ì˜ì´ ì¤‘ìš”**

### 5.2 ë„ì „ 2: Windows vs Linux ê²½ë¡œ ì°¨ì´

**ë¬¸ì œ:**
ë¡œì»¬ ê°œë°œ(Windows) â†’ EC2 ë°°í¬(Linux)ì—ì„œ ê²½ë¡œ ê´€ë ¨ ë²„ê·¸ ë°œìƒ

```python
# âŒ Windowsì—ì„œëŠ” ì‘ë™, Linuxì—ì„œ ì‹¤íŒ¨
file_path = "_posts\\learning\\2025-10-17-post.md"

# âŒ ë¬¸ìì—´ ê²°í•©
file_path = "_posts" + "/" + "learning" + "/" + filename

# âœ… pathlib ì‚¬ìš©
from pathlib import Path
file_path = Path("_posts") / "learning" / filename
```

**í•´ê²°:**
```python
# í¬ë¡œìŠ¤ í”Œë«í¼ ì½”ë“œ
from pathlib import Path

class Config:
    PROJECT_ROOT = Path(__file__).parent.parent
    POSTS_DIR = PROJECT_ROOT / "_posts"
    DATA_DIR = PROJECT_ROOT / "data"
    
    # ì¹´í…Œê³ ë¦¬ë³„ ë””ë ‰í† ë¦¬
    LEARNING_DIR = POSTS_DIR / "learning"
    QA_ENGINEER_DIR = POSTS_DIR / "qa-engineer"
```

**ë°°ìš´ ì :**
- `pathlib.Path` ì‚¬ìš© â†’ OS ë…ë¦½ì 
- ì ˆëŒ€ ê²½ë¡œ í•˜ë“œì½”ë”© ê¸ˆì§€
- ëª¨ë“  ê²½ë¡œë¥¼ `Path` ê°ì²´ë¡œ ê´€ë¦¬

### 5.3 ë„ì „ 3: Systemd ì„œë¹„ìŠ¤ Node.js ê²½ë¡œ

**ë¬¸ì œ:**
nvmìœ¼ë¡œ ì„¤ì¹˜í•œ Node.js ê²½ë¡œê°€ ë™ì ìœ¼ë¡œ ë³€ê²½ë¨

```bash
# ë¬¸ì œ: ë²„ì „ë§ˆë‹¤ ë‹¤ë¥¸ ê²½ë¡œ
/home/ubuntu/.nvm/versions/node/v18.20.4/bin/node
/home/ubuntu/.nvm/versions/node/v18.20.5/bin/node
```

**ì˜ëª»ëœ ì ‘ê·¼:**
```ini
# âŒ í•˜ë“œì½”ë”©
[Service]
ExecStart=/home/ubuntu/.nvm/versions/node/v18.20.5/bin/npx ...
```

**í•´ê²°:**
```bash
# âœ… ë™ì  ê°ì§€
NODE_VERSION=$(node --version | sed 's/v//')
NODE_PATH="$HOME/.nvm/versions/node/v$NODE_VERSION/bin"

# systemd ì„œë¹„ìŠ¤ì— ì ìš©
cat > /tmp/mcp-sequentialthinking.service << EOF
[Service]
Environment="PATH=$NODE_PATH:/usr/local/bin:/usr/bin:/bin"
ExecStart=$NODE_PATH/npx -y @modelcontextprotocol/server-sequentialthinking
EOF
```

**ë°°ìš´ ì :**
- ì„¤ì¹˜ ì‹œì ì— ê²½ë¡œ ë™ì  ìƒì„±
- ë²„ì „ ì—…ë°ì´íŠ¸ì— ìœ ì—°í•˜ê²Œ ëŒ€ì‘

### 5.4 ë„ì „ 4: GitHub Push ì¸ì¦

**ë¬¸ì œ:**
EC2ì—ì„œ ìë™ìœ¼ë¡œ GitHubì— í‘¸ì‹œí•˜ë ¤ë©´ ì¸ì¦ í•„ìš”

**ì‹œë„í•œ ë°©ë²•ë“¤:**

**1) HTTPS + Personal Access Token**
```bash
# Git credential helper ì„¤ì •
git config --global credential.helper store

# í•œ ë²ˆ ìˆ˜ë™ìœ¼ë¡œ í‘¸ì‹œí•˜ë©´ì„œ í† í° ì…ë ¥
git push
# Username: your-username
# Password: ghp_your_token_here

# ì´í›„ ìë™ìœ¼ë¡œ ì €ì¥ë¨
```

**ì¥ì :** ê°„ë‹¨, ë¹ ë¦„  
**ë‹¨ì :** í† í°ì´ í‰ë¬¸ìœ¼ë¡œ ì €ì¥ (`~/.git-credentials`)

**2) SSH í‚¤ (ìµœì¢… ì„ íƒ)**
```bash
# SSH í‚¤ ìƒì„±
ssh-keygen -t ed25519 -C "bot@geeknews.local"

# ê³µê°œ í‚¤ë¥¼ GitHubì— ë“±ë¡
cat ~/.ssh/id_ed25519.pub

# Git ì›ê²© ì €ì¥ì†Œë¥¼ SSHë¡œ ë³€ê²½
git remote set-url origin git@github.com:username/repo.git

# ì—°ê²° í…ŒìŠ¤íŠ¸
ssh -T git@github.com
```

**ì¥ì :** ë” ì•ˆì „, í‚¤ í˜ì–´ ë°©ì‹  
**ë‹¨ì :** ì´ˆê¸° ì„¤ì • ë³µì¡

**ìµœì¢… ì„ íƒ: SSH**  
â†’ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ë³´ì•ˆì´ ìš°ì„ 

### 5.5 ë„ì „ 5: ë©”ëª¨ë¦¬ ìµœì í™” (t2.micro 1GB RAM)

**ë¬¸ì œ:**
Python + Node.js + MCPê°€ ë™ì‹œì— ì‹¤í–‰ë˜ë©´ ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©:**
```
Python venv:        ~250MB
Node.js MCP:        ~200MB
ì‹¤í–‰ ì‹œ Python:     ~400MB
ì‹¤í–‰ ì‹œ OpenAI:     ~100MB
-------------------------
Peak:               ~950MB (1GB ì´ˆê³¼!)
```

**í•´ê²° 1: systemd ë¦¬ì†ŒìŠ¤ ì œí•œ**
```ini
# MCP ì„œë²„
[Service]
MemoryMax=256M
CPUQuota=25%

# GeekNews
[Service]
MemoryMax=512M
CPUQuota=50%
```

**í•´ê²° 2: ìŠ¤ì™‘ ë©”ëª¨ë¦¬ ì¶”ê°€**
```bash
# 1GB ìŠ¤ì™‘ íŒŒì¼ ìƒì„±
sudo fallocate -l 1G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# ì˜êµ¬ ì ìš©
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

**í•´ê²° 3: ì‹¤í–‰ ìµœì í™”**
```python
# OpenAI API í˜¸ì¶œ ì‹œ ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™”
stream=False  # ë©”ëª¨ë¦¬ ë²„í¼ ê°ì†Œ

# MCP depth ì œí•œ
depth = min(int(os.getenv("MCP_THINKING_DEPTH", "3")), 3)
```

**ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©:**
```
Python venv:        ~250MB
Node.js MCP:        ~150MB (ì œí•œ ì ìš©)
ì‹¤í–‰ ì‹œ Python:     ~350MB (ì œí•œ ì ìš©)
ì‹¤í–‰ ì‹œ OpenAI:     ~80MB
Swap ì‚¬ìš©:          ~100MB
-------------------------
Peak:               ~830MB + 100MB swap
âœ… ì•ˆì •ì  ìš´ì˜!
```

---

## 6. í•µì‹¬ ë°°ìš´ ì 

### 6.1 ê¸°ìˆ ì  êµí›ˆ

#### 1. í‘œì¤€ í”„ë¡œí† ì½œì˜ í˜

**MCP ì„ íƒì´ ì˜³ì•˜ë˜ ì´ìœ :**

- âœ… **ìƒíƒœê³„**: ë‹¤ë¥¸ MCP ì„œë²„(Memory, RAG, Database ë“±)ë„ ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥
- âœ… **ìœ ì§€ë³´ìˆ˜**: ì»¤ë®¤ë‹ˆí‹°ì˜ ë²„ê·¸ ìˆ˜ì • ë° ê°œì„  í˜œíƒ
- âœ… **í•™ìŠµ**: í•œ ë²ˆ ë°°ìš°ë©´ ë‹¤ë¥¸ MCP í”„ë¡œì íŠ¸ì—ë„ ì ìš©

**ë¯¸ë˜ í™•ì¥ ê°€ëŠ¥ì„±:**
```python
# í˜„ì¬
mcp_thinking = SequentialThinkingClient()

# ë¯¸ë˜
mcp_memory = MemoryClient()      # ì´ì „ ë¶„ì„ ê¸°ì–µ
mcp_rag = RAGClient()            # ì™¸ë¶€ ë¬¸ì„œ ê²€ìƒ‰
mcp_code = CodeAnalysisClient()  # ì½”ë“œ ì˜ˆì œ ë¶„ì„

# í†µí•©
result = {
    "thinking": mcp_thinking.think(problem),
    "related": mcp_memory.recall(problem),
    "docs": mcp_rag.search(problem),
    "code": mcp_code.analyze(code_snippet)
}
```

#### 2. í´ë°±ì˜ ì¤‘ìš”ì„±

**ì‹œìŠ¤í…œ ì‹ ë¢°ì„± = í´ë°± ì „ëµ**

```python
# ê³„ì¸µì  í´ë°±
def generate_content(item):
    # Level 1: MCP + OpenAI (ìµœê³  í’ˆì§ˆ)
    if mcp_available and openai_available:
        return mcp_openai_generate(item)
    
    # Level 2: OpenAI only (ì¤‘ê°„ í’ˆì§ˆ)
    elif openai_available:
        return openai_generate(item)
    
    # Level 3: Rule-based (ê¸°ë³¸ í’ˆì§ˆ)
    else:
        return rule_based_generate(item)
```

**24/7 ë¬´ì¸ ìš´ì˜ì˜ í•µì‹¬:**
- ì–´ë–¤ ì»´í¬ë„ŒíŠ¸ê°€ ë‹¤ìš´ë˜ì–´ë„ ì‹œìŠ¤í…œì€ ê³„ì† ì‘ë™
- í’ˆì§ˆì€ ë–¨ì–´ì§€ë”ë¼ë„ ì„œë¹„ìŠ¤ëŠ” ìœ ì§€

#### 3. ì¸í”„ë¼ ìë™í™”

**ìˆ˜ë™ ì‘ì—… = ì˜¤ë¥˜ì˜ ì›ì¸**

```bash
# âŒ ìˆ˜ë™ ë°°í¬ (ì˜¤ë¥˜ ë‹¤ë°œ)
ssh ubuntu@ec2
cd my-blog-cli
git pull
source venv/bin/activate
pip install -r requirements.txt
sudo systemctl restart geeknews

# âœ… ìë™ ë°°í¬ (ì¼ê´€ì„±)
bash deploy/deploy.sh
# ìœ„ ëª¨ë“  ê³¼ì • ìë™í™” + ë°±ì—… + í—¬ìŠ¤ì²´í¬
```

**ë°°ìš´ ì :**
- í•œ ë²ˆ ìŠ¤í¬ë¦½íŠ¸ë¡œ ë§Œë“¤ë©´ ì˜ì›íˆ ì¬ì‚¬ìš©
- ì˜¤ë¥˜ ë°œìƒë¥  90% ê°ì†Œ
- ìƒˆë¡œìš´ íŒ€ì›ë„ ì‰½ê²Œ ë°°í¬ ê°€ëŠ¥

### 6.2 ì•„í‚¤í…ì²˜ êµí›ˆ

#### 1. ê³„ì¸µ ë¶„ë¦¬ (Separation of Concerns)

**ì¢‹ì€ ì•„í‚¤í…ì²˜:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  í‘œí˜„ì¸µ (CLI, API)                   â”‚
â”‚  - ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤                 â”‚
â”‚  - íŒŒë¼ë¯¸í„° íŒŒì‹±                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì¸µ                     â”‚
â”‚  - Pipeline, Generator, Filter      â”‚
â”‚  - í•µì‹¬ ë„ë©”ì¸ ë¡œì§                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì¸í”„ë¼ì¸µ                            â”‚
â”‚  - MCP Client, Git, OpenAI          â”‚
â”‚  - ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ì´ì :**
- ê° ê³„ì¸µì„ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- MCPë¥¼ ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë¡œ êµì²´ ì‰¬ì›€
- ëª¨í‚¹(Mocking)ì´ ê°„ë‹¨

**ë‚˜ìœ ì˜ˆ:**
```python
# âŒ ëª¨ë“  ê²ƒì´ í•œ íŒŒì¼ì—
def run():
    items = parse_rss()  # ë°ì´í„° ìˆ˜ì§‘
    for item in items:
        mcp_result = call_mcp()  # MCP í˜¸ì¶œ
        openai_result = call_openai()  # OpenAI í˜¸ì¶œ
        write_file()  # íŒŒì¼ ì“°ê¸°
        git_push()  # Git í‘¸ì‹œ
    # í…ŒìŠ¤íŠ¸ ë¶ˆê°€ëŠ¥, ì¬ì‚¬ìš© ë¶ˆê°€ëŠ¥
```

#### 2. ì„¤ì • ì™¸ë¶€í™” (Configuration Externalization)

**í™˜ê²½ ë³€ìˆ˜ë¡œ ëª¨ë“  ì„¤ì • ê´€ë¦¬:**
```python
# config.py
class Config:
    # OpenAI
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    
    # MCP
    ENABLE_MCP = os.getenv("ENABLE_MCP", "true").lower() == "true"
    MCP_SERVER_URL = os.getenv("MCP_SERVER_URL", "http://localhost:3000")
    MCP_THINKING_DEPTH = int(os.getenv("MCP_THINKING_DEPTH", "3"))
    
    # Git
    AUTO_GIT_PUSH = os.getenv("AUTO_GIT_PUSH", "true").lower() == "true"
```

**ì´ì :**
- ì½”ë“œ ìˆ˜ì • ì—†ì´ ì„¤ì • ë³€ê²½
- ê°œë°œ/ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ í™˜ê²½ ë¶„ë¦¬
- ë¯¼ê° ì •ë³´(API í‚¤) ì½”ë“œì—ì„œ ë¶„ë¦¬

### 6.3 í”„ë¡œì„¸ìŠ¤ êµí›ˆ

#### 1. ì ì§„ì  í†µí•© (Incremental Integration)

**ë‹¨ê³„ë³„ ì ‘ê·¼:**
```
Week 1: âœ… ê¸°ë³¸ ì‹œìŠ¤í…œ êµ¬ì¶• (OpenAIë§Œ)
        â†’ ì‘ë™ í™•ì¸ â†’ í”„ë¡œë•ì…˜ ë°°í¬

Week 2: âœ… MCP ì¶”ê°€ (ì„ íƒì )
        â†’ A/B í…ŒìŠ¤íŠ¸ â†’ í’ˆì§ˆ ë¹„êµ

Week 3: âœ… Git ìë™í™” ì¶”ê°€
        â†’ ìˆ˜ë™ ê²€ì¦ â†’ ìë™í™” í™œì„±í™”

Week 4: âœ… EC2 ë°°í¬
        â†’ ëª¨ë‹ˆí„°ë§ â†’ ìµœì í™”
```

**ì´ì :**
- ê° ë‹¨ê³„ë§ˆë‹¤ ê²€ì¦
- ë¬¸ì œ ë°œìƒ ì‹œ ë¹ ë¥¸ ë¡¤ë°±
- íŒ€ì›ë“¤ì˜ ì ì§„ì  í•™ìŠµ

**ì•ˆ ì¢‹ì€ ì˜ˆ:**
```
Day 1: MCP + Git + EC2 + Monitoring ëª¨ë‘ ë™ì‹œ ê°œë°œ
     â†“
Day 7: ë²„ê·¸ íˆ¬ì„±ì´, ì–´ë””ì„œ ë¬¸ì œì¸ì§€ ëª¨ë¦„
     â†“
Day 14: ì „ì²´ ì¬ì‘ì„±
```

#### 2. ë¬¸ì„œí™”ì˜ ì¤‘ìš”ì„±

**ì´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ê°€ ë°”ë¡œ ìì‚°:**

- âœ… **ì™œ** ì´ë ‡ê²Œ ë§Œë“¤ì—ˆëŠ”ì§€
- âœ… **ì–´ë–¤** ëŒ€ì•ˆì„ ê³ ë ¤í–ˆëŠ”ì§€
- âœ… **ë¬´ì—‡ì„** ë°°ì› ëŠ”ì§€

**6ê°œì›” í›„:**
- "ì™œ MCPë¥¼ ì„ íƒí–ˆì§€?" â†’ ì´ ë¬¸ì„œ ì°¸ê³ 
- "Git ìë™í™”ëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ì§€?" â†’ ì½”ë“œ + ì´ ë¬¸ì„œ

**1ë…„ í›„:**
- ìƒˆë¡œìš´ íŒ€ì› ì˜¨ë³´ë”© â†’ ì´ ë¬¸ì„œ ì½ê¸°
- ë¹„ìŠ·í•œ í”„ë¡œì íŠ¸ ì‹œì‘ â†’ ì´ ë¬¸ì„œ í…œí”Œë¦¿ í™œìš©

---

## 7. ì„±ê³¼ ë° ì¸¡ì •

### 7.1 ì •ëŸ‰ì  ì„±ê³¼

#### Before vs After

| ì§€í‘œ | Before | After | ê°œì„  |
|------|--------|-------|------|
| **ì‹œê°„ íˆ¬ì** | 10ë¶„/ì¼ | 0ë¶„/ì¼ | **100% ì ˆê°** |
| **ì—°ê°„ ì‹œê°„** | 60ì‹œê°„ | 0ì‹œê°„ | **60ì‹œê°„ ì ˆê°** |
| **ë¶„ì„ ê¹Šì´** | 1ë‹¨ê³„ | 3ë‹¨ê³„ | **200% í–¥ìƒ** |
| **í¬ìŠ¤íŠ¸ í’ˆì§ˆ** | ì¤‘ê°„ | ë†’ìŒ | **ì£¼ê´€ì ** |
| **ìš´ì˜ ì•ˆì •ì„±** | ìˆ˜ë™ | 24/7 ìë™ | **ë¬´ì¸ ìš´ì˜** |

#### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ (t2.micro)

```
CPU ì‚¬ìš©ë¥ :
- í‰ê· : 8-12%
- í”¼í¬: 45% (MCP + OpenAI ë™ì‹œ ì‹¤í–‰)
- ìœ íœ´: 5%

ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:
- í‰ê· : 450MB
- í”¼í¬: 830MB
- ìŠ¤ì™‘: 100MB

ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰:
- ì½”ë“œ: ~300MB
- ì˜ì¡´ì„±: ~200MB
- ë¡œê·¸: ~50MB/ì›”
- ì´: ~550MB
```

**ê²°ë¡ : t2.micro(ë¬´ë£Œ í‹°ì–´)ì—ì„œ ì¶©ë¶„íˆ ìš´ì˜ ê°€ëŠ¥!**

#### ë¹„ìš© ë¶„ì„

```
AWS EC2 (t2.micro):          $0/ì›” (ë¬´ë£Œ í‹°ì–´)
OpenAI API:                  $60/ì›” (ê¸°ì¡´ ë™ì¼)
MCP ì¶”ê°€ ë¹„ìš©:               $0 (ì˜¤í”ˆì†ŒìŠ¤)
GitHub:                      $0 (ë¬´ë£Œ)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ ë¹„ìš©:                     $60/ì›”

ì ˆê°ëœ ì‹œê°„ ê°€ì¹˜:
60ì‹œê°„/ë…„ Ã— $50/ì‹œê°„ = $3,000/ë…„
```

**ROI: ê°œë°œ 2ì¼ íˆ¬ì â†’ ì—°ê°„ $3,000 ì‹œê°„ ì ˆê°**

### 7.2 ì •ì„±ì  ì„±ê³¼

#### ì½˜í…ì¸  í’ˆì§ˆ í–¥ìƒ

**Before (OpenAI only):**
```markdown
## QA Engineerê°€ ì•Œì•„ì•¼ í•  ì 

- ì´ ê¸°ìˆ ì€ í…ŒìŠ¤íŠ¸ ìë™í™”ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.
- ì£¼ì˜ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤.
- í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.
```

**After (MCP + OpenAI):**
```markdown
## QA Engineerê°€ ì•Œì•„ì•¼ í•  í•µì‹¬ ë‚´ìš©

1. **í…ŒìŠ¤íŠ¸ íŒ¨ëŸ¬ë‹¤ì„ ë³€í™”**: ì´ ê¸°ìˆ ì€ ë‹¨ìˆœíˆ ë„êµ¬ê°€ ì•„ë‹ˆë¼ 
   QA í”„ë¡œì„¸ìŠ¤ ì „ì²´ë¥¼ ì¬ì„¤ê³„í•˜ë„ë¡ ìš”êµ¬í•©ë‹ˆë‹¤. 
   ì „í†µì ì¸ ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ ìë™í™”ì—ì„œ AI ê¸°ë°˜ ì§€ëŠ¥í˜• í…ŒìŠ¤íŠ¸ë¡œ 
   ì „í™˜ë˜ë©°, í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±ë¶€í„° ê²°í•¨ ì˜ˆì¸¡ê¹Œì§€ 
   ì „ ê³¼ì •ì´ ë³€í™”í•©ë‹ˆë‹¤. (MCP ì‚¬ê³  ê³¼ì • ë°˜ì˜)

2. **ì‹¤ë¬´ ì ìš© ê³ ë ¤ì‚¬í•­**: ë„ì… ì‹œ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì¸í”„ë¼ì™€ì˜ 
   í†µí•©ì´ ê°€ì¥ í° ê³¼ì œì…ë‹ˆë‹¤. Jenkins/GitLab CIì™€ì˜ ì—°ë™, 
   í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬, íŒ€ì› êµìœ¡ ë“± ë‹¤ê°ë„ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤. 
   (MCP ì¸ì‚¬ì´íŠ¸ í™œìš©)

3. **ìœ„í—˜ ê´€ë¦¬**: AIì˜ í•œê³„ë¥¼ ì´í•´í•˜ê³  ì¸ê°„ ê²€ì¦ì„ 
   ë³‘í–‰í•´ì•¼ í•©ë‹ˆë‹¤. íŠ¹íˆ ë³´ì•ˆ í…ŒìŠ¤íŠ¸ë‚˜ ì»´í”Œë¼ì´ì–¸ìŠ¤ 
   ê²€ì¦ì—ì„œëŠ” AI ê²°ê³¼ë¥¼ ë§¹ì‹ í•˜ì§€ ë§ê³  ì „ë¬¸ê°€ ë¦¬ë·°ë¥¼ 
   ê±°ì³ì•¼ í•©ë‹ˆë‹¤. (MCP ê²°ë¡  ë°˜ì˜)
```

**ì°¨ì´ì :**
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì 
- ë‹¤ê°ë„ ë¶„ì„ (íŒ¨ëŸ¬ë‹¤ì„, ì‹¤ë¬´, ìœ„í—˜)
- ì‚¬ê³  ê³¼ì •ì´ ë“œëŸ¬ë‚¨

#### ì‹œìŠ¤í…œ ì‹ ë¢°ì„±

```
ê°€ë™ ì‹œê°„:
- ëª©í‘œ: 99% (24/7 ì¤‘ 23.76ì‹œê°„)
- ì‹¤ì œ: 99.5% (ì‹œìŠ¤í…œ ì¬ë¶€íŒ… ì‹œë§Œ ë‹¤ìš´)

ìë™ ë³µêµ¬:
- systemd restart on failure
- MCP ì„œë²„ ë‹¤ìš´ â†’ ìë™ ì¬ì‹œì‘
- Python ì˜¤ë¥˜ â†’ ë‹¤ìŒ ì‹œê°„ì— ì¬ì‹œë„

ëª¨ë‹ˆí„°ë§:
- journalctlë¡œ ì‹¤ì‹œê°„ ë¡œê·¸
- í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸ (ì£¼ê°„ ì‹¤í–‰)
```

---

## 8. ì¬í˜„ ê°€ëŠ¥í•œ ê°€ì´ë“œ

### 8.1 ë¡œì»¬ ê°œë°œ í™˜ê²½ (5ë¶„)

```bash
# Windows PowerShell ê¸°ì¤€

# 1. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-username/my-blog-cli.git
cd my-blog-cli

# 2. Python ê°€ìƒí™˜ê²½
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt

# 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp env.example .env
# .env íŒŒì¼ í¸ì§‘:
# OPENAI_API_KEY=sk-...
# ENABLE_MCP=false  (ë¡œì»¬ì—ì„œëŠ” MCP ì—†ì´)

# 4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python scripts/run_once.py

# 5. ìƒì„±ëœ í¬ìŠ¤íŠ¸ í™•ì¸
ls _posts/learning/
ls _posts/qa-engineer/
```

### 8.2 EC2 ë°°í¬ (15ë¶„)

#### ì‚¬ì „ ì¤€ë¹„

1. **AWS EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„±**
   - AMI: Ubuntu 22.04 LTS
   - ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•: t2.micro (ë¬´ë£Œ í‹°ì–´)
   - ë³´ì•ˆ ê·¸ë£¹: SSH(22) í—ˆìš©
   - ìŠ¤í† ë¦¬ì§€: 16GB

2. **GitHub ì €ì¥ì†Œ ì¤€ë¹„**
   - ì´ í”„ë¡œì íŠ¸ë¥¼ GitHubì— í‘¸ì‹œ
   - GitHub Pages í™œì„±í™” (Settings â†’ Pages)

#### ë°°í¬ ì‹¤í–‰

```bash
# 1. EC2 ì ‘ì†
ssh -i "your-key.pem" ubuntu@your-ec2-ip

# 2. í”„ë¡œì íŠ¸ í´ë¡ 
git clone https://github.com/your-username/my-blog-cli.git
cd my-blog-cli

# 3. ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
bash deploy/setup_ec2.sh
# í”„ë¡¬í”„íŠ¸: systemd íƒ€ì´ë¨¸ ì„ íƒ (ì˜µì…˜ 2)

# 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
nano .env
# OPENAI_API_KEY=sk-...
# ENABLE_MCP=true
# AUTO_GIT_PUSH=true
# GIT_USER_NAME="GeekNews Bot"
# GIT_USER_EMAIL="your-email@example.com"

# 5. GitHub SSH í‚¤ ì„¤ì •
ssh-keygen -t ed25519 -C "your-email@example.com"
cat ~/.ssh/id_ed25519.pub
# ì¶œë ¥ëœ ê³µê°œ í‚¤ë¥¼ GitHub â†’ Settings â†’ SSH keysì— ë“±ë¡

ssh -T git@github.com
# "Hi username!" ë©”ì‹œì§€ í™•ì¸

# 6. Git ì›ê²© ì €ì¥ì†Œ ì„¤ì •
git remote set-url origin git@github.com:your-username/my-blog-cli.git

# 7. í—¬ìŠ¤ì²´í¬
source venv/bin/activate
python scripts/health_check.py
# ëª¨ë“  í•­ëª© âœ… í™•ì¸

# 8. ìˆ˜ë™ í…ŒìŠ¤íŠ¸
python scripts/run_once.py
# í¬ìŠ¤íŠ¸ ìƒì„± â†’ Git push í™•ì¸

# 9. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
sudo systemctl status mcp-sequentialthinking
systemctl list-timers geeknews.timer
```

#### ëª¨ë‹ˆí„°ë§

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸
sudo journalctl -u mcp-sequentialthinking -f
sudo journalctl -u geeknews-oneshot -f

# ìµœê·¼ ì‹¤í–‰ ë¡œê·¸
sudo journalctl -u geeknews-oneshot -n 100

# ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„
systemctl list-timers geeknews.timer
```

### 8.3 íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

#### ë¬¸ì œ 1: MCP ì„œë²„ ì‹œì‘ ì•ˆ ë¨

```bash
# ì¦ìƒ
sudo systemctl status mcp-sequentialthinking
# Active: failed

# ì§„ë‹¨
sudo journalctl -u mcp-sequentialthinking -n 50
# Node.js ê²½ë¡œ ì˜¤ë¥˜

# í•´ê²°
# Node.js ì¬ì„¤ì¹˜
source ~/.nvm/nvm.sh
nvm install 18
nvm use 18

# ì„œë¹„ìŠ¤ ì¬ì‹œì‘
sudo systemctl restart mcp-sequentialthinking
```

#### ë¬¸ì œ 2: GitHub Push ì‹¤íŒ¨

```bash
# ì¦ìƒ
âš ï¸ Git ìë™ í‘¸ì‹œ ì‹¤íŒ¨: Permission denied

# ì§„ë‹¨
ssh -T git@github.com
# Permission denied (publickey)

# í•´ê²°
# SSH í‚¤ ì¬ìƒì„±
ssh-keygen -t ed25519 -C "your-email@example.com"
cat ~/.ssh/id_ed25519.pub
# GitHubì— ì¬ë“±ë¡

# ì—°ê²° í…ŒìŠ¤íŠ¸
ssh -T git@github.com
# Hi username! í™•ì¸
```

#### ë¬¸ì œ 3: ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# ì¦ìƒ
Killed (í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ)

# ì§„ë‹¨
free -h
# Mem: 1G, Used: 950M, Available: 50M

# í•´ê²°
# ìŠ¤ì™‘ ë©”ëª¨ë¦¬ ì¶”ê°€
sudo fallocate -l 1G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab

# í™•ì¸
free -h
# Swap: 1G
```

---

## 9. ë‹¤ìŒ ë‹¨ê³„ì™€ ë¯¸ë˜ ê³„íš

### 9.1 ë‹¨ê¸° ê°œì„  (1-3ê°œì›”)

#### 1. ë©€í‹° MCP ì„œë²„ í†µí•©

```python
# í˜„ì¬
mcp_thinking = SequentialThinkingClient()

# ê³„íš
class MultiMCPClient:
    def __init__(self):
        self.thinking = SequentialThinkingClient()
        self.memory = MemoryMCPClient()  # ê³¼ê±° ë¶„ì„ ê¸°ì–µ
        self.rag = RAGMCPClient()        # ë¬¸ì„œ ê²€ìƒ‰
    
    def enhanced_analysis(self, item):
        # 1. ê³¼ê±° ìœ ì‚¬ ê¸°ì‚¬ ê²€ìƒ‰
        related = self.memory.search_similar(item['title'])
        
        # 2. ì™¸ë¶€ ë¬¸ì„œ ê²€ìƒ‰
        docs = self.rag.search(item['title'])
        
        # 3. í†µí•© ë¶„ì„
        result = self.thinking.think(
            problem=item['title'],
            context={
                "related_articles": related,
                "reference_docs": docs
            }
        )
        
        return result
```

#### 2. A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬

```python
# MCP vs Non-MCP í’ˆì§ˆ ë¹„êµ
class QualityMetrics:
    def evaluate(self, post):
        return {
            "readability": calculate_readability(post),
            "depth": calculate_depth(post),
            "actionability": calculate_actionability(post)
        }

# ì‹¤í—˜
for item in items:
    post_a = generate_without_mcp(item)
    post_b = generate_with_mcp(item)
    
    metrics_a = evaluate(post_a)
    metrics_b = evaluate(post_b)
    
    log_comparison(metrics_a, metrics_b)
```

#### 3. ì½˜í…ì¸  í’ˆì§ˆ ëª¨ë‹ˆí„°ë§

```python
# Prometheus + Grafana
metrics = {
    "posts_generated": Counter,
    "mcp_analysis_time": Histogram,
    "openai_tokens": Counter,
    "git_push_success": Counter
}

# ëŒ€ì‹œë³´ë“œ
- ì¼ë³„ í¬ìŠ¤íŠ¸ ìƒì„± ìˆ˜
- MCP ë¶„ì„ ì‹œê°„ ì¶”ì´
- OpenAI ë¹„ìš© ì¶”ì´
- ì‹œìŠ¤í…œ ê°€ë™ë¥ 
```

### 9.2 ì¤‘ê¸° ëª©í‘œ (3-6ê°œì›”)

#### 1. ë©€í‹° ëª¨ë¸ ì „ëµ

```python
# ë‹¤ì–‘í•œ LLM í™œìš©
class MultiModelGenerator:
    def generate(self, item):
        # GPT-4o-mini: ë¹ ë¥¸ ë¶„ì„
        quick = openai_generate(item, model="gpt-4o-mini")
        
        # Claude: ê¹Šì´ ìˆëŠ” ë¶„ì„
        deep = anthropic_generate(item, model="claude-3-sonnet")
        
        # Gemini: ë‹¤ì–‘í•œ ê´€ì 
        diverse = google_generate(item, model="gemini-pro")
        
        # ì•™ìƒë¸”
        return ensemble([quick, deep, diverse])
```

#### 2. ìë™ SEO ìµœì í™”

```python
# í‚¤ì›Œë“œ ì¶”ì¶œ ë° ìµœì í™”
def optimize_seo(post):
    # ë©”íƒ€ íƒœê·¸ ìƒì„±
    keywords = extract_keywords(post['content'])
    meta = generate_meta_description(post['summary'])
    
    # ë‚´ë¶€ ë§í¬ ì¶”ê°€
    related_posts = find_related_posts(keywords)
    post['internal_links'] = related_posts
    
    # ì´ë¯¸ì§€ alt í…ìŠ¤íŠ¸
    post['images'] = add_alt_text(post['images'], keywords)
    
    return post
```

#### 3. ë…ì ì°¸ì—¬ ë¶„ì„

```python
# Google Analytics í†µí•©
def analyze_engagement():
    ga = GoogleAnalytics()
    
    # ì¸ê¸° í¬ìŠ¤íŠ¸ ë¶„ì„
    top_posts = ga.get_top_posts()
    
    # MCP ì‚¬ìš© ì—¬ë¶€ë³„ ì„±ê³¼
    mcp_posts = filter_posts(with_mcp=True)
    non_mcp_posts = filter_posts(with_mcp=False)
    
    comparison = {
        "mcp_avg_time": calculate_avg_time(mcp_posts),
        "non_mcp_avg_time": calculate_avg_time(non_mcp_posts),
        "mcp_bounce_rate": calculate_bounce(mcp_posts),
        "non_mcp_bounce_rate": calculate_bounce(non_mcp_posts)
    }
    
    return comparison
```

### 9.3 ì¥ê¸° ë¹„ì „ (6-12ê°œì›”)

#### 1. ì¸í„°ë™í‹°ë¸Œ ë¸”ë¡œê·¸

```python
# ë…ì ì§ˆë¬¸ì— ì‹¤ì‹œê°„ ë‹µë³€
class InteractiveBlog:
    def answer_question(self, post_id, question):
        post = load_post(post_id)
        
        # MCPë¡œ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
        context = mcp_thinking.analyze_question(
            question=question,
            post_context=post['content']
        )
        
        # ë‹µë³€ ìƒì„±
        answer = openai.generate_answer(
            question=question,
            context=context
        )
        
        return answer
```

#### 2. ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥í•œ ì½˜í…ì¸ 

```python
# ë…ì ë ˆë²¨ì— ë”°ë¼ ì½˜í…ì¸  ì¡°ì •
def customize_content(post, reader_level):
    if reader_level == "beginner":
        # ê¸°ë³¸ ê°œë… ì¶”ê°€, ì „ë¬¸ ìš©ì–´ ì„¤ëª…
        post = add_fundamentals(post)
        post = explain_jargon(post)
    elif reader_level == "advanced":
        # ì‹¬í™” ë‚´ìš© ì¶”ê°€, ì½”ë“œ ì˜ˆì‹œ í™•ì¥
        post = add_advanced_topics(post)
        post = expand_code_examples(post)
    
    return post
```

#### 3. ìë™ ë²ˆì—­ ë° ë‹¤êµ­ì–´ ì§€ì›

```python
# í¬ìŠ¤íŠ¸ ìë™ ë²ˆì—­
def auto_translate(post):
    translations = {}
    
    for language in ["en", "ja", "zh"]:
        translated = translate_with_context(
            post['content'],
            target_lang=language,
            preserve_code=True,
            preserve_urls=True
        )
        
        translations[language] = translated
    
    return translations
```

---

## 10. ë§ˆì¹˜ë©°

### 10.1 ì´ í”„ë¡œì íŠ¸ì˜ ì§„ì§œ ê°€ì¹˜

ì´ ì‹œìŠ¤í…œì˜ ì§„ì •í•œ ê°€ì¹˜ëŠ” **"ìë™í™”"**ê°€ ì•„ë‹™ë‹ˆë‹¤.

**ì§„ì§œ ê°€ì¹˜ëŠ”:**

1. **ë¬¸ì œë¥¼ ëª…í™•íˆ ì •ì˜í•˜ëŠ” ëŠ¥ë ¥**
   - "AIê°€ ë” ê¹Šì´ ìƒê°í•˜ê²Œ í•˜ë ¤ë©´?"

2. **ê¸°ìˆ  ì„ íƒì˜ ê·¼ê±°ë¥¼ ì„¤ëª…í•˜ëŠ” ëŠ¥ë ¥**
   - "ì™œ MCPì¸ê°€? ë‹¤ë¥¸ ëŒ€ì•ˆì€?"

3. **íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì´í•´í•˜ê³  ìˆ˜ìš©í•˜ëŠ” ëŠ¥ë ¥**
   - "ë³µì¡ë„ëŠ” ì¦ê°€í•˜ì§€ë§Œ í™•ì¥ì„±ì„ ì–»ëŠ”ë‹¤"

4. **ì ì§„ì ìœ¼ë¡œ ê°œì„ í•˜ëŠ” ëŠ¥ë ¥**
   - í•œ ë²ˆì— ì™„ë²½í•˜ê²Œ ë§Œë“¤ ìˆ˜ ì—†ë‹¤

5. **ê³¼ì •ì„ ê¸°ë¡í•˜ëŠ” ëŠ¥ë ¥**
   - ì´ ê¸€ì´ ë°”ë¡œ ê·¸ ì¦ê±°

### 10.2 AI ì‹œëŒ€ì˜ ì—”ì§€ë‹ˆì–´ë§

2025ë…„, AI ë„êµ¬ëŠ” ë„˜ì³ë‚©ë‹ˆë‹¤.

**ì¤‘ìš”í•œ ê²ƒì€:**
- âŒ "ë¬´ì—‡ì„ ë§Œë“¤ì—ˆëŠ”ê°€?"
- âœ… **"ì™œ, ì–´ë–»ê²Œ ë§Œë“¤ì—ˆëŠ”ê°€?"**

ì´ ê¸€ì„ ì“°ë©´ì„œ ê¹¨ë‹¬ì€ ê²ƒ:

> **"AIë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤, AIë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í• ì§€ ì„¤ê³„í•˜ëŠ” ê²ƒì´ ë” ì¤‘ìš”í•˜ë‹¤."**

MCPëŠ” ë„êµ¬ì¼ ë¿ì…ë‹ˆë‹¤.  
ì§„ì§œ ìì‚°ì€ **ì´ ì—¬ì •ì„ í†µí•´ ë°°ìš´ ì‚¬ê³ ë°©ì‹**ì…ë‹ˆë‹¤.

### 10.3 ë…ì ì—¬ëŸ¬ë¶„ê»˜

ì´ ê¸€ì´ ì—¬ëŸ¬ë¶„ì˜ í”„ë¡œì íŠ¸ì— ì˜ê°ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤.

**í–‰ë™ ì œì•ˆ:**

1. **ë³µì‚¬í•˜ì§€ ë§ê³  ì´í•´í•˜ì„¸ìš”**
   - ì½”ë“œë¥¼ ë³µë¶™í•˜ëŠ” ê²ƒì€ ì‰½ìŠµë‹ˆë‹¤
   - ì™œ ê·¸ë ‡ê²Œ ì„¤ê³„ë˜ì—ˆëŠ”ì§€ ì´í•´í•˜ì„¸ìš”

2. **ìì‹ ë§Œì˜ ë¬¸ì œë¥¼ ì°¾ìœ¼ì„¸ìš”**
   - ì´ í”„ë¡œì íŠ¸ëŠ” ì œ ë¬¸ì œë¥¼ í‘¼ ê²ƒì…ë‹ˆë‹¤
   - ì—¬ëŸ¬ë¶„ì˜ ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?

3. **ê³¼ì •ì„ ê¸°ë¡í•˜ì„¸ìš”**
   - 6ê°œì›” í›„ì˜ ìì‹ ì—ê²Œ ì„¤ëª…í•˜ì„¸ìš”
   - ê·¸ê²ƒì´ ì§„ì§œ ìì‚°ì…ë‹ˆë‹¤

### 10.4 ì—°ë½ì²˜ ë° ê¸°ì—¬

**í”„ë¡œì íŠ¸ ì €ì¥ì†Œ:**  
https://github.com/your-username/my-blog-cli

**ê¸°ì—¬ í™˜ì˜:**
- Issue: ë²„ê·¸ ë¦¬í¬íŠ¸, ê¸°ëŠ¥ ì œì•ˆ
- PR: ì½”ë“œ ê°œì„ , ë¬¸ì„œ ë³´ì™„
- Discussion: ì•„ì´ë””ì–´ ê³µìœ 

**ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´:**
- GitHub Discussions
- ì´ í¬ìŠ¤íŠ¸ ëŒ“ê¸€

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [MCP ê³µì‹ ë¬¸ì„œ](https://github.com/modelcontextprotocol/servers)
- [MCP Sequential Thinking](https://github.com/modelcontextprotocol/servers/tree/main/src/sequentialthinking)
- [OpenAI API ë¬¸ì„œ](https://platform.openai.com/docs)
- [AWS EC2 ê°€ì´ë“œ](https://docs.aws.amazon.com/ec2/)
- [systemd ë¬¸ì„œ](https://www.freedesktop.org/software/systemd/man/)

### ê´€ë ¨ ë…¼ë¬¸
- Chain-of-Thought Prompting
- Self-Consistency with CoT
- Agent Protocol Standards

### ì°¸ê³  í”„ë¡œì íŠ¸
- FastMCP (Python MCP í”„ë ˆì„ì›Œí¬)
- MCP Registry (ë‹¤ì–‘í•œ MCP ì„œë²„)

---

**í”„ë¡œì íŠ¸ í†µê³„:**

```
ê°œë°œ ê¸°ê°„:     2ì¼
ì½”ë“œ ë¼ì¸:     ~2,500 lines
ì‹ ê·œ íŒŒì¼:     8ê°œ
ìˆ˜ì • íŒŒì¼:     8ê°œ
ì˜ì¡´ì„±:        Python 3.11, Node.js 18, httpx, OpenAI
ì‘ì„± ì‹œê°„:     ì´ í¬ìŠ¤íŠ¸ 8ì‹œê°„
```

**íƒœê·¸:** #MCP #ModelContextProtocol #SequentialThinking #AI #Automation #EC2 #AWS #Python #NodeJS #DevOps #SystemDesign #LearningInPublic #EngineeringJourney #TechBlog

---

**ì´ í¬ìŠ¤íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆë‚˜ìš”?**  
â­ GitHub Starë¡œ ì‘ì›í•´ì£¼ì„¸ìš”!  
ğŸ“ ì—¬ëŸ¬ë¶„ì˜ ê²½í—˜ë„ ëŒ“ê¸€ë¡œ ê³µìœ í•´ì£¼ì„¸ìš”!

**ë‹¤ìŒ í¬ìŠ¤íŠ¸ ì˜ˆê³ :**  
"MCP Memory Server í†µí•©: AIê°€ ê³¼ê±°ë¥¼ ê¸°ì–µí•˜ê²Œ ë§Œë“¤ê¸°"

